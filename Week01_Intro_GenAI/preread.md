# Week 01: Pre-Reading Materials

## Required Reading
1. **"Attention Is All You Need"** - Vaswani et al. (2017)
   - Focus on understanding the transformer architecture fundamentals

2. **"Generative Adversarial Networks"** - Goodfellow et al. (2014)
   - Introduction to GANs and their applications

## Recommended Reading
1. **"The Illustrated Transformer"** - Jay Alammar
   - Visual explanation of transformer architecture
   - URL: http://jalammar.github.io/illustrated-transformer/

2. **"What are Large Language Models?"** - IBM Research
   - Overview of LLMs and their capabilities

## Videos to Watch
1. **"Introduction to Generative AI"** - Google Cloud (30 minutes)
2. **"The Future of AI"** - Andrej Karpathy (45 minutes)

## Preparation Questions
1. What is the difference between discriminative and generative models?
2. How do transformers differ from previous neural network architectures?
3. What are some potential applications of generative AI in your field of interest?

## Estimated Reading Time: 2-3 hours 