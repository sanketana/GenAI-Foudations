{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c23f384",
   "metadata": {},
   "source": [
    "# üöÄ Embeddings: From Theory to RAG Applications\n",
    "\n",
    "## Welcome to Week 4: Embeddings Deep Dive!\n",
    "\n",
    "This notebook will take you on a journey from basic vector concepts to advanced RAG (Retrieval-Augmented Generation) applications. We'll build understanding progressively with lots of practical examples.\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand vector spaces and mathematical foundations\n",
    "- Master embedding concepts through intuitive examples\n",
    "- Learn semantic similarity and search techniques\n",
    "- Apply embeddings in RAG systems\n",
    "- Build practical applications step-by-step\n",
    "\n",
    "### üìö Prerequisites\n",
    "- Basic Python knowledge\n",
    "- Understanding of lists and arrays\n",
    "- Curiosity to learn! üß†\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9473852e",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Imports\n",
    "\n",
    "Let's start by importing the necessary libraries for our journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# For embeddings\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Utilities\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c329396",
   "metadata": {},
   "source": [
    "## üîß Environment Setup\n",
    "\n",
    "Make sure you have your OpenAI API key set up. If you don't have one, you can still follow along with the theoretical concepts and use alternative embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbdd204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained embedding model\n",
    "print(\"üì• Loading embedding model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight, fast model\n",
    "print(\"‚úÖ Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437a8046",
   "metadata": {},
   "source": [
    "## üéØ Section 1: Understanding Vectors - The Foundation\n",
    "\n",
    "Before we dive into embeddings, let's understand the fundamental building blocks: **vectors** and **vector spaces**.\n",
    "\n",
    "### What is a Vector?\n",
    "\n",
    "Think of a vector as a list of numbers that represents a point in space. Just like how your GPS coordinates (latitude, longitude) tell you where you are on Earth, a vector tells you where something is in a mathematical space.\n",
    "\n",
    "Let's start with simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Simple 2D Vectors (like GPS coordinates)\n",
    "print(\"üìç 2D Vector Examples (like GPS coordinates)\")\n",
    "\n",
    "# Vector representing a point in 2D space\n",
    "point_a = [3, 4]  # x=3, y=4\n",
    "point_b = [1, 2]  # x=1, y=2\n",
    "\n",
    "print(f\"Point A: {point_a}\")\n",
    "print(f\"Point B: {point_b}\")\n",
    "\n",
    "# Visualize these points\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter([point_a[0]], [point_a[1]], color='red', s=100, label='Point A (3,4)')\n",
    "plt.scatter([point_b[0]], [point_b[1]], color='blue', s=100, label='Point B (1,2)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('2D Vector Visualization')\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Example 2: 3D Vectors (like 3D coordinates)\n",
    "print(\"\\nüåç 3D Vector Examples (like 3D coordinates)\")\n",
    "\n",
    "# Vector representing a point in 3D space\n",
    "point_3d = [2, 3, 5]  # x=2, y=3, z=5\n",
    "print(f\"3D Point: {point_3d}\")\n",
    "\n",
    "# Example 3: High-dimensional vectors (like embeddings!)\n",
    "print(\"\\nüß† High-dimensional Vector Example (like embeddings)\")\n",
    "# A 5-dimensional vector (much smaller than real embeddings which can be 768+ dimensions)\n",
    "embedding_example = [0.1, -0.3, 0.8, 0.2, -0.5]\n",
    "print(f\"5D Embedding Vector: {embedding_example}\")\n",
    "print(f\"Length of vector: {len(embedding_example)} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947afe9",
   "metadata": {},
   "source": [
    "## üî¢ Section 2: Vector Operations - The Math Behind Similarity\n",
    "\n",
    "Now let's learn the key mathematical operations that make embeddings powerful: **dot product** and **cosine similarity**.\n",
    "\n",
    "### Dot Product: The Foundation of Similarity\n",
    "\n",
    "The dot product measures how much two vectors point in the same direction. It's like asking: \"How similar are these two directions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding Dot Product with Intuitive Examples\n",
    "\n",
    "# Example 1: Simple 2D vectors\n",
    "vector_a = np.array([3, 4])\n",
    "vector_b = np.array([1, 2])\n",
    "\n",
    "# Manual calculation\n",
    "dot_product_manual = vector_a[0] * vector_b[0] + vector_a[1] * vector_b[1]\n",
    "dot_product_numpy = np.dot(vector_a, vector_b)\n",
    "\n",
    "print(f\"Vector A: {vector_a}\")\n",
    "print(f\"Vector B: {vector_b}\")\n",
    "print(f\"Dot Product (manual): {dot_product_manual}\")\n",
    "print(f\"Dot Product (numpy): {dot_product_numpy}\")\n",
    "\n",
    "# Visualize the vectors\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot vectors\n",
    "plt.quiver(0, 0, vector_a[0], vector_a[1], angles='xy', scale_units='xy', scale=1, color='red', label='Vector A')\n",
    "plt.quiver(0, 0, vector_b[0], vector_b[1], angles='xy', scale_units='xy', scale=1, color='blue', label='Vector B')\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Vector Visualization for Dot Product')\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.xlim(-1, 5)\n",
    "plt.ylim(-1, 5)\n",
    "plt.show()\n",
    "\n",
    "# Example 2: Different scenarios\n",
    "print(\"\\nüîç Dot Product in Different Scenarios:\")\n",
    "\n",
    "# Scenario 1: Parallel vectors (pointing same direction)\n",
    "parallel_a = np.array([2, 0])\n",
    "parallel_b = np.array([4, 0])\n",
    "dot_parallel = np.dot(parallel_a, parallel_b)\n",
    "print(f\"Parallel vectors: {parallel_a} and {parallel_b}\")\n",
    "print(f\"Dot product: {dot_parallel} (high positive value)\")\n",
    "\n",
    "# Scenario 2: Perpendicular vectors (90 degrees)\n",
    "perpendicular_a = np.array([2, 0])\n",
    "perpendicular_b = np.array([0, 3])\n",
    "dot_perpendicular = np.dot(perpendicular_a, perpendicular_b)\n",
    "print(f\"\\nPerpendicular vectors: {perpendicular_a} and {perpendicular_b}\")\n",
    "print(f\"Dot product: {dot_perpendicular} (zero!)\")\n",
    "\n",
    "# Scenario 3: Opposite vectors (180 degrees)\n",
    "opposite_a = np.array([2, 0])\n",
    "opposite_b = np.array([-2, 0])\n",
    "dot_opposite = np.dot(opposite_a, opposite_b)\n",
    "print(f\"\\nOpposite vectors: {opposite_a} and {opposite_b}\")\n",
    "print(f\"Dot product: {dot_opposite} (negative value)\")\n",
    "\n",
    "print(\"\\nüí° Key Insight: Dot product tells us about the 'alignment' of vectors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e183a83f",
   "metadata": {},
   "source": [
    "## üìê Section 3: Cosine Similarity - The Magic Formula\n",
    "\n",
    "While dot product is useful, it has a problem: it depends on the magnitude (length) of vectors. We want to measure similarity regardless of size.\n",
    "\n",
    "**Cosine Similarity** solves this by normalizing the dot product by the magnitudes of both vectors.\n",
    "\n",
    "### The Formula:\n",
    "```\n",
    "cosine_similarity = dot_product / (magnitude_a * magnitude_b)\n",
    "```\n",
    "\n",
    "This gives us a value between -1 and 1:\n",
    "- **1**: Vectors point in exactly the same direction (most similar)\n",
    "- **0**: Vectors are perpendicular (no similarity)\n",
    "- **-1**: Vectors point in opposite directions (least similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding Cosine Similarity\n",
    "\n",
    "def cosine_similarity_manual(a, b):\n",
    "    \"\"\"Calculate cosine similarity manually\"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    magnitude_a = np.linalg.norm(a)\n",
    "    magnitude_b = np.linalg.norm(b)\n",
    "    return dot_product / (magnitude_a * magnitude_b)\n",
    "\n",
    "# Example 1: Same direction, different magnitudes\n",
    "vector_1 = np.array([1, 1])\n",
    "vector_2 = np.array([2, 2])  # Same direction, twice the magnitude\n",
    "\n",
    "dot_product = np.dot(vector_1, vector_2)\n",
    "cosine_sim = cosine_similarity_manual(vector_1, vector_2)\n",
    "\n",
    "print(f\"Vector 1: {vector_1}, Magnitude: {np.linalg.norm(vector_1):.2f}\")\n",
    "print(f\"Vector 2: {vector_2}, Magnitude: {np.linalg.norm(vector_2):.2f}\")\n",
    "print(f\"Dot Product: {dot_product}\")\n",
    "print(f\"Cosine Similarity: {cosine_sim:.3f} (Perfect similarity!)\")\n",
    "\n",
    "# Example 2: Different angles\n",
    "angles = [0, 45, 90, 135, 180]  # degrees\n",
    "similarities = []\n",
    "\n",
    "for angle in angles:\n",
    "    # Create vectors at different angles\n",
    "    rad = np.radians(angle)\n",
    "    vector_a = np.array([1, 0])\n",
    "    vector_b = np.array([np.cos(rad), np.sin(rad)])\n",
    "    \n",
    "    sim = cosine_similarity_manual(vector_a, vector_b)\n",
    "    similarities.append(sim)\n",
    "    print(f\"Angle: {angle}¬∞, Cosine Similarity: {sim:.3f}\")\n",
    "\n",
    "# Visualize the relationship\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(angles, similarities, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Angle (degrees)')\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.title('Cosine Similarity vs Angle')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "plt.axhline(y=1, color='green', linestyle='--', alpha=0.5, label='Perfect Similarity')\n",
    "plt.axhline(y=-1, color='red', linestyle='--', alpha=0.5, label='Opposite')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Show some example vectors\n",
    "example_vectors = [\n",
    "    ([1, 0], [1, 0], '0¬∞ (Same)'),\n",
    "    ([1, 0], [0.7, 0.7], '45¬∞'),\n",
    "    ([1, 0], [0, 1], '90¬∞ (Perpendicular)'),\n",
    "    ([1, 0], [-0.7, 0.7], '135¬∞'),\n",
    "    ([1, 0], [-1, 0], '180¬∞ (Opposite)')\n",
    "]\n",
    "\n",
    "for i, (v1, v2, label) in enumerate(example_vectors):\n",
    "    plt.quiver(0, 0, v1[0], v1[1], angles='xy', scale_units='xy', scale=1, \n",
    "               color='red', alpha=0.7, width=0.02)\n",
    "    plt.quiver(0, 0, v2[0], v2[1], angles='xy', scale_units='xy', scale=1, \n",
    "               color='blue', alpha=0.7, width=0.02)\n",
    "    plt.text(v2[0]*1.2, v2[1]*1.2, label, fontsize=8)\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Vector Angles and Similarity')\n",
    "plt.axis('equal')\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Key Insight: Cosine similarity measures direction similarity, not magnitude!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a59171",
   "metadata": {},
   "source": [
    "## üß† Section 4: What are Embeddings? - The Bridge to AI\n",
    "\n",
    "Now that we understand vectors and similarity, let's dive into **embeddings** - the magical way we convert text, images, or any data into vectors that capture meaning.\n",
    "\n",
    "### The Big Idea\n",
    "\n",
    "An embedding is a way to represent complex data (like text) as a vector of numbers in a high-dimensional space, where:\n",
    "- **Similar meanings** are close together\n",
    "- **Different meanings** are far apart\n",
    "- **Semantic relationships** are preserved\n",
    "\n",
    "Think of it like this: If you could plot all words in a 3D space, \"king\" and \"queen\" would be close, \"king\" and \"apple\" would be far apart, and \"king\" - \"man\" + \"woman\" would be close to \"queen\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding Embeddings with Simple Examples\n",
    "\n",
    "# Example 1: Simple word embeddings (conceptual)\n",
    "print(\"üî§ Simple Word Embeddings Example\")\n",
    "\n",
    "# Let's create a simple 3D embedding space for words\n",
    "word_embeddings = {\n",
    "    'king': [0.8, 0.2, 0.1],      # High royalty, low gender, low object\n",
    "    'queen': [0.8, 0.8, 0.1],     # High royalty, high gender, low object\n",
    "    'man': [0.2, 0.2, 0.1],       # Low royalty, low gender, low object\n",
    "    'woman': [0.2, 0.8, 0.1],     # Low royalty, high gender, low object\n",
    "    'apple': [0.1, 0.1, 0.9],     # Low royalty, low gender, high object\n",
    "    'banana': [0.1, 0.1, 0.8]     # Low royalty, low gender, high object\n",
    "}\n",
    "\n",
    "# Convert to numpy arrays for easier manipulation\n",
    "embeddings_array = np.array(list(word_embeddings.values()))\n",
    "words = list(word_embeddings.keys())\n",
    "\n",
    "print(\"Word Embeddings (3D vectors):\")\n",
    "for word, embedding in word_embeddings.items():\n",
    "    print(f\"{word:8}: {embedding}\")\n",
    "\n",
    "# Calculate similarities\n",
    "print(\"\\nüîç Similarity Analysis:\")\n",
    "for i, word1 in enumerate(words):\n",
    "    for j, word2 in enumerate(words[i+1:], i+1):\n",
    "        sim = cosine_similarity([embeddings_array[i]], [embeddings_array[j]])[0][0]\n",
    "        print(f\"{word1:8} vs {word2:8}: {sim:.3f}\")\n",
    "\n",
    "# Visualize in 3D\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']\n",
    "for i, (word, embedding) in enumerate(word_embeddings.items()):\n",
    "    ax.scatter(embedding[0], embedding[1], embedding[2], \n",
    "               c=colors[i], s=100, label=word)\n",
    "    ax.text(embedding[0], embedding[1], embedding[2], word, fontsize=12)\n",
    "\n",
    "ax.set_xlabel('Royalty')\n",
    "ax.set_ylabel('Gender')\n",
    "ax.set_zlabel('Object-ness')\n",
    "ax.set_title('Simple 3D Word Embeddings')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Notice how similar words (king/queen, apple/banana) are close together!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804a446c",
   "metadata": {},
   "source": [
    "## üìä Section 5: TF-IDF - The Simple Text Embedding Method\n",
    "\n",
    "Before we dive into modern neural embeddings, let's understand **TF-IDF** (Term Frequency-Inverse Document Frequency), a classic method that's still useful today.\n",
    "\n",
    "### What is TF-IDF?\n",
    "\n",
    "TF-IDF converts text into vectors based on word frequency, giving more weight to rare, important words.\n",
    "\n",
    "- **TF (Term Frequency)**: How often a word appears in a document\n",
    "- **IDF (Inverse Document Frequency)**: How rare a word is across all documents\n",
    "- **TF-IDF Score**: TF √ó IDF = Importance of word in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff71430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Example: Document Similarity\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"The dog sat on the floor\", \n",
    "    \"The cat and dog are pets\",\n",
    "    \"The weather is sunny today\",\n",
    "    \"The cat is sleeping on the mat\"\n",
    "]\n",
    "\n",
    "print(\"üìÑ Sample Documents:\")\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "# Create TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"\\nüî§ Vocabulary: {feature_names}\")\n",
    "print(f\"üìä TF-IDF Matrix Shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "# Show TF-IDF scores for first document\n",
    "print(\"\\nüìà TF-IDF Scores for Document 1:\")\n",
    "doc1_scores = tfidf_matrix[0].toarray()[0]\n",
    "for word, score in zip(feature_names, doc1_scores):\n",
    "    if score > 0:\n",
    "        print(f\"{word:10}: {score:.3f}\")\n",
    "\n",
    "# Calculate similarities between all documents\n",
    "similarities = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "print(\"\\nüîç Document Similarities:\")\n",
    "print(\"      \", end=\"\")\n",
    "for i in range(len(documents)):\n",
    "    print(f\"Doc{i+1:6}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i in range(len(documents)):\n",
    "    print(f\"Doc{i+1:6}\", end=\"\")\n",
    "    for j in range(len(documents)):\n",
    "        print(f\"{similarities[i][j]:6.3f}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "# Visualize similarities\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(similarities, \n",
    "            xticklabels=[f'Doc{i+1}' for i in range(len(documents))],\n",
    "            yticklabels=[f'Doc{i+1}' for i in range(len(documents))],\n",
    "            annot=True, cmap='Blues', vmin=0, vmax=1)\n",
    "plt.title('Document Similarity Matrix (TF-IDF)')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Notice how documents with similar words (1, 3, 5) have higher similarity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7330971",
   "metadata": {},
   "source": [
    "## ü§ñ Section 6: Modern Neural Embeddings - The Power of AI\n",
    "\n",
    "TF-IDF is good, but it has limitations:\n",
    "- Doesn't understand word meanings\n",
    "- \"bank\" (financial) and \"bank\" (river) are treated the same\n",
    "- No understanding of context\n",
    "\n",
    "**Neural embeddings** solve these problems by learning semantic relationships from vast amounts of text data.\n",
    "\n",
    "### How Neural Embeddings Work\n",
    "\n",
    "1. **Training**: Model reads millions of sentences\n",
    "2. **Learning**: Understands word relationships and context\n",
    "3. **Output**: Each word/text gets a high-dimensional vector (384-1536 dimensions)\n",
    "4. **Magic**: Similar meanings = similar vectors, regardless of exact words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed81fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modern Neural Embeddings Example\n",
    "\n",
    "# Sample texts with similar meanings but different words\n",
    "texts = [\n",
    "    \"The cat is sleeping on the mat\",\n",
    "    \"A feline is resting on the carpet\",\n",
    "    \"The weather is sunny today\",\n",
    "    \"It's a beautiful day with clear skies\",\n",
    "    \"I love eating pizza\",\n",
    "    \"Pizza is my favorite food\",\n",
    "    \"The bank is closed today\",\n",
    "    \"The financial institution is not open\",\n",
    "    \"The river bank is muddy\",\n",
    "    \"The shore of the stream is wet\"\n",
    "]\n",
    "\n",
    "print(\"üìù Sample Texts:\")\n",
    "for i, text in enumerate(texts, 1):\n",
    "    print(f\"{i:2}. {text}\")\n",
    "\n",
    "# Generate embeddings using our model\n",
    "print(\"\\nüîÑ Generating embeddings...\")\n",
    "embeddings = model.encode(texts)\n",
    "\n",
    "print(f\"üìä Embedding shape: {embeddings.shape}\")\n",
    "print(f\"üî¢ Each text is now a {embeddings.shape[1]}-dimensional vector!\")\n",
    "\n",
    "# Calculate similarities\n",
    "similarities = cosine_similarity(embeddings)\n",
    "\n",
    "print(\"\\nüîç Neural Embedding Similarities:\")\n",
    "print(\"      \", end=\"\")\n",
    "for i in range(len(texts)):\n",
    "    print(f\"T{i+1:3}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    print(f\"T{i+1:3}\", end=\"\")\n",
    "    for j in range(len(texts)):\n",
    "        print(f\"{similarities[i][j]:5.3f}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "# Find most similar pairs\n",
    "print(\"\\nüéØ Most Similar Text Pairs:\")\n",
    "pairs = []\n",
    "for i in range(len(texts)):\n",
    "    for j in range(i+1, len(texts)):\n",
    "        pairs.append((i, j, similarities[i][j]))\n",
    "\n",
    "# Sort by similarity\n",
    "pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "for i, j, sim in pairs[:5]:\n",
    "    print(f\"Similarity {sim:.3f}:\")\n",
    "    print(f\"  Text {i+1}: {texts[i]}\")\n",
    "    print(f\"  Text {j+1}: {texts[j]}\")\n",
    "    print()\n",
    "\n",
    "# Visualize in 2D using PCA\n",
    "print(\"üìà Visualizing embeddings in 2D...\")\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=100, alpha=0.7)\n",
    "\n",
    "# Add text labels\n",
    "for i, (x, y) in enumerate(embeddings_2d):\n",
    "    plt.annotate(f'T{i+1}', (x, y), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('Text Embeddings in 2D Space (PCA)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Key Insights:\")\n",
    "print(\"1. Similar meanings cluster together (cat/feline, weather/sunny)\")\n",
    "print(\"2. Different meanings are separated (bank financial vs bank river)\")\n",
    "print(\"3. Semantic similarity > word overlap!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e5bff",
   "metadata": {},
   "source": [
    "## üîç Section 7: Semantic Search - Finding Meaning, Not Just Words\n",
    "\n",
    "Now let's build a **semantic search engine** - the core component of RAG systems. Instead of finding exact word matches, we find documents with similar meanings.\n",
    "\n",
    "### How Semantic Search Works\n",
    "\n",
    "1. **Index**: Convert all documents to embeddings\n",
    "2. **Query**: Convert search query to embedding\n",
    "3. **Search**: Find documents with most similar embeddings\n",
    "4. **Rank**: Return results ranked by similarity\n",
    "\n",
    "This is much more powerful than traditional keyword search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Semantic Search Engine\n",
    "\n",
    "# Sample knowledge base (like documents in a RAG system)\n",
    "knowledge_base = [\n",
    "    \"Python is a popular programming language for data science and machine learning.\",\n",
    "    \"Machine learning algorithms can learn patterns from data without explicit programming.\",\n",
    "    \"Deep learning uses neural networks with multiple layers to solve complex problems.\",\n",
    "    \"Natural language processing helps computers understand human language.\",\n",
    "    \"Data visualization is important for understanding and communicating insights.\",\n",
    "    \"Artificial intelligence aims to create systems that can perform tasks requiring human intelligence.\",\n",
    "    \"Big data refers to large datasets that are difficult to process using traditional methods.\",\n",
    "    \"Cloud computing provides on-demand access to computing resources over the internet.\",\n",
    "    \"Cybersecurity protects computer systems from theft, damage, and unauthorized access.\",\n",
    "    \"Blockchain is a distributed ledger technology that ensures secure and transparent transactions.\"\n",
    "]\n",
    "\n",
    "print(\"üìö Knowledge Base Documents:\")\n",
    "for i, doc in enumerate(knowledge_base, 1):\n",
    "    print(f\"{i:2}. {doc}\")\n",
    "\n",
    "# Create embeddings for all documents\n",
    "print(\"\\nüîÑ Creating document embeddings...\")\n",
    "doc_embeddings = model.encode(knowledge_base)\n",
    "\n",
    "print(f\"üìä Embedding shape: {doc_embeddings.shape}\")\n",
    "\n",
    "# Function for semantic search\n",
    "def semantic_search(query, doc_embeddings, documents, top_k=3):\n",
    "    \"\"\"Perform semantic search\"\"\"\n",
    "    # Encode the query\n",
    "    query_embedding = model.encode([query])\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
    "    \n",
    "    # Get top-k results\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            'document': documents[idx],\n",
    "            'similarity': similarities[idx],\n",
    "            'index': idx\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test different queries\n",
    "test_queries = [\n",
    "    \"How do computers learn from data?\",\n",
    "    \"What is the best programming language for AI?\",\n",
    "    \"How can we protect our data?\",\n",
    "    \"What technology is used for secure transactions?\"\n",
    "]\n",
    "\n",
    "print(\"\\nüîç Testing Semantic Search:\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\n‚ùì Query: {query}\")\n",
    "    results = semantic_search(query, doc_embeddings, knowledge_base, top_k=3)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{i}. Similarity: {result['similarity']:.3f}\")\n",
    "        print(f\"   Doc {result['index']+1}: {result['document']}\")\n",
    "        print()\n",
    "\n",
    "# Interactive search demo\n",
    "print(\"üéØ Interactive Search Demo:\")\n",
    "print(\"Try these queries or type your own:\")\n",
    "print(\"- 'neural networks'\")\n",
    "print(\"- 'data analysis'\")\n",
    "print(\"- 'computer security'\")\n",
    "print(\"- 'distributed systems'\")\n",
    "\n",
    "# You can uncomment this for interactive search\n",
    "# while True:\n",
    "#     query = input(\"\\nEnter your search query (or 'quit' to exit): \")\n",
    "#     if query.lower() == 'quit':\n",
    "#         break\n",
    "#     \n",
    "#     results = semantic_search(query, doc_embeddings, knowledge_base, top_k=3)\n",
    "#     print(f\"\\nüîç Results for: {query}\")\n",
    "#     for i, result in enumerate(results, 1):\n",
    "#         print(f\"{i}. Similarity: {result['similarity']:.3f}\")\n",
    "#         print(f\"   {result['document']}\")\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d2ada",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Section 8: RAG Architecture - Where Embeddings Fit In\n",
    "\n",
    "Now let's understand how embeddings power **RAG (Retrieval-Augmented Generation)** systems.\n",
    "\n",
    "### RAG Architecture Overview\n",
    "\n",
    "```\n",
    "User Query ‚Üí Embedding ‚Üí Vector Search ‚Üí Relevant Documents ‚Üí LLM ‚Üí Answer\n",
    "     ‚Üì           ‚Üì            ‚Üì              ‚Üì              ‚Üì\n",
    "   Text      Vector      Similarity      Context       Response\n",
    "```\n",
    "\n",
    "### The Role of Embeddings in RAG\n",
    "\n",
    "1. **Document Indexing**: Convert knowledge base to embeddings\n",
    "2. **Query Processing**: Convert user question to embedding\n",
    "3. **Retrieval**: Find most similar documents using vector similarity\n",
    "4. **Context**: Pass relevant documents to LLM for answer generation\n",
    "\n",
    "This is why embeddings are crucial for RAG - they enable semantic retrieval!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcff34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RAG System Implementation\n",
    "\n",
    "# Simulate a knowledge base about AI/ML topics\n",
    "ai_knowledge_base = [\n",
    "    \"Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed.\",\n",
    "    \"Deep learning uses artificial neural networks with multiple layers to model and understand complex patterns in data.\",\n",
    "    \"Natural language processing (NLP) is a branch of AI that helps computers understand, interpret, and generate human language.\",\n",
    "    \"Computer vision is a field of AI that trains computers to interpret and understand visual information from the world.\",\n",
    "    \"Reinforcement learning is a type of machine learning where an agent learns to make decisions by taking actions in an environment to achieve maximum rewards.\",\n",
    "    \"Supervised learning uses labeled training data to teach models to make predictions or classifications.\",\n",
    "    \"Unsupervised learning finds hidden patterns in data without predefined labels or outcomes.\",\n",
    "    \"Transfer learning allows models to apply knowledge learned from one task to a related task.\",\n",
    "    \"Neural networks are computing systems inspired by biological neural networks in human brains.\",\n",
    "    \"Convolutional neural networks (CNNs) are particularly effective for image recognition and computer vision tasks.\"\n",
    "]\n",
    "\n",
    "print(\"üìö AI/ML Knowledge Base:\")\n",
    "for i, doc in enumerate(ai_knowledge_base, 1):\n",
    "    print(f\"{i:2}. {doc}\")\n",
    "\n",
    "# Create embeddings\n",
    "print(\"\\nüîÑ Creating embeddings...\")\n",
    "kb_embeddings = model.encode(ai_knowledge_base)\n",
    "\n",
    "# Simple RAG function\n",
    "def simple_rag_system(query, knowledge_base, embeddings, top_k=2):\n",
    "    \"\"\"Simple RAG system implementation\"\"\"\n",
    "    \n",
    "    print(f\"\\nü§ñ RAG System Processing: {query}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Step 1: Convert query to embedding\n",
    "    query_embedding = model.encode([query])\n",
    "    print(\"‚úÖ Step 1: Query converted to embedding\")\n",
    "    \n",
    "    # Step 2: Find similar documents\n",
    "    similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    print(f\"‚úÖ Step 2: Found {top_k} most similar documents\")\n",
    "    \n",
    "    # Step 3: Retrieve relevant context\n",
    "    relevant_docs = []\n",
    "    for idx in top_indices:\n",
    "        relevant_docs.append({\n",
    "            'content': knowledge_base[idx],\n",
    "            'similarity': similarities[idx],\n",
    "            'index': idx\n",
    "        })\n",
    "        print(f\"   üìÑ Doc {idx+1} (similarity: {similarities[idx]:.3f}): {knowledge_base[idx][:80]}...\")\n",
    "    \n",
    "    # Step 4: Generate response (simulated)\n",
    "    print(\"\\n‚úÖ Step 3: Generating response based on retrieved context...\")\n",
    "    \n",
    "    # Simulate LLM response\n",
    "    response = f\"Based on the retrieved information, here's what I found about '{query}':\\n\\n\"\n",
    "    \n",
    "    for i, doc in enumerate(relevant_docs, 1):\n",
    "        response += f\"{i}. {doc['content']}\\n\\n\"\n",
    "    \n",
    "    response += f\"These documents were selected based on semantic similarity to your query.\"\n",
    "    \n",
    "    return response, relevant_docs\n",
    "\n",
    "# Test the RAG system\n",
    "test_questions = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How do neural networks work?\",\n",
    "    \"What is the difference between supervised and unsupervised learning?\",\n",
    "    \"How does computer vision work?\"\n",
    "]\n",
    "\n",
    "print(\"\\nüß™ Testing RAG System:\")\n",
    "for question in test_questions:\n",
    "    response, docs = simple_rag_system(question, ai_knowledge_base, kb_embeddings)\n",
    "    print(response)\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"üéØ Key RAG Insights:\")\n",
    "print(\"1. Embeddings enable semantic document retrieval\")\n",
    "print(\"2. Retrieved context improves LLM responses\")\n",
    "print(\"3. Similarity scores help rank relevance\")\n",
    "print(\"4. RAG combines the best of retrieval and generation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa4b00",
   "metadata": {},
   "source": [
    "## üöÄ Section 9: Advanced Topics - Taking It Further\n",
    "\n",
    "Let's explore some advanced concepts and practical considerations for embeddings in production systems.\n",
    "\n",
    "### Dimensionality Reduction for Visualization\n",
    "\n",
    "High-dimensional embeddings (384-1536 dimensions) are hard to visualize. We use techniques like **PCA** and **t-SNE** to reduce them to 2D/3D for visualization.\n",
    "\n",
    "### Embedding Models Comparison\n",
    "\n",
    "Different models have different strengths:\n",
    "- **all-MiniLM-L6-v2**: Fast, good for general use\n",
    "- **all-mpnet-base-v2**: Better quality, slower\n",
    "- **OpenAI text-embedding-ada-002**: High quality, requires API\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "- **Vector Databases**: Pinecone, Weaviate, Chroma for storing embeddings\n",
    "- **Indexing**: HNSW, IVF for fast similarity search\n",
    "- **Caching**: Store frequently used embeddings\n",
    "- **Batch Processing**: Process multiple texts efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189fedc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Topics: Dimensionality Reduction and Model Comparison\n",
    "\n",
    "# Let's create a larger dataset for visualization\n",
    "topics = [\n",
    "    \"machine learning algorithms\",\n",
    "    \"deep learning neural networks\", \n",
    "    \"natural language processing\",\n",
    "    \"computer vision systems\",\n",
    "    \"reinforcement learning agents\",\n",
    "    \"supervised learning models\",\n",
    "    \"unsupervised learning clustering\",\n",
    "    \"transfer learning techniques\",\n",
    "    \"artificial intelligence systems\",\n",
    "    \"data science analytics\",\n",
    "    \"big data processing\",\n",
    "    \"cloud computing services\",\n",
    "    \"cybersecurity protection\",\n",
    "    \"blockchain technology\",\n",
    "    \"internet of things devices\"\n",
    "]\n",
    "\n",
    "print(\"üìä Creating embeddings for visualization...\")\n",
    "topic_embeddings = model.encode(topics)\n",
    "\n",
    "print(f\"Original embedding shape: {topic_embeddings.shape}\")\n",
    "\n",
    "# PCA for dimensionality reduction\n",
    "print(\"\\nüìà Applying PCA for 2D visualization...\")\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_pca = pca.fit_transform(topic_embeddings)\n",
    "\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total variance explained: {sum(pca.explained_variance_ratio_):.3f}\")\n",
    "\n",
    "# t-SNE for better clustering visualization\n",
    "print(\"\\nüé® Applying t-SNE for better clustering...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=5)\n",
    "embeddings_tsne = tsne.fit_transform(topic_embeddings)\n",
    "\n",
    "# Visualize both methods\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# PCA visualization\n",
    "scatter1 = ax1.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1], s=100, alpha=0.7)\n",
    "ax1.set_xlabel('PCA Component 1')\n",
    "ax1.set_ylabel('PCA Component 2')\n",
    "ax1.set_title('PCA Dimensionality Reduction')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add labels for PCA\n",
    "for i, topic in enumerate(topics):\n",
    "    ax1.annotate(f'{i+1}', (embeddings_pca[i, 0], embeddings_pca[i, 1]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "# t-SNE visualization\n",
    "scatter2 = ax2.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1], s=100, alpha=0.7)\n",
    "ax2.set_xlabel('t-SNE Component 1')\n",
    "ax2.set_ylabel('t-SNE Component 2')\n",
    "ax2.set_title('t-SNE Dimensionality Reduction')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add labels for t-SNE\n",
    "for i, topic in enumerate(topics):\n",
    "    ax2.annotate(f'{i+1}', (embeddings_tsne[i, 0], embeddings_tsne[i, 1]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show topic numbers\n",
    "print(\"\\nüìã Topic Reference:\")\n",
    "for i, topic in enumerate(topics, 1):\n",
    "    print(f\"{i:2}. {topic}\")\n",
    "\n",
    "print(\"\\nüîç Observations:\")\n",
    "print(\"1. PCA preserves global structure but may not show clusters clearly\")\n",
    "print(\"2. t-SNE better preserves local structure and shows clusters\")\n",
    "print(\"3. Similar topics (ML/DL/NLP) tend to cluster together\")\n",
    "print(\"4. Different domains (AI vs IoT vs Blockchain) are separated\")\n",
    "\n",
    "# Model comparison (conceptual)\n",
    "print(\"\\nü§ñ Model Comparison Table:\")\n",
    "models_info = [\n",
    "    [\"all-MiniLM-L6-v2\", \"384\", \"Fast\", \"Good\", \"General purpose\"],\n",
    "    [\"all-mpnet-base-v2\", \"768\", \"Medium\", \"Better\", \"Quality-focused\"],\n",
    "    [\"OpenAI ada-002\", \"1536\", \"Slow\", \"Best\", \"Production-ready\"]\n",
    "]\n",
    "\n",
    "print(f\"{'Model':<20} {'Dim':<6} {'Speed':<8} {'Quality':<8} {'Use Case':<15}\")\n",
    "print(\"-\" * 60)\n",
    "for model_info in models_info:\n",
    "    print(f\"{model_info[0]:<20} {model_info[1]:<6} {model_info[2]:<8} {model_info[3]:<8} {model_info[4]:<15}\")\n",
    "\n",
    "print(\"\\nüí° Choose based on your needs: speed vs quality vs cost!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f30a9e",
   "metadata": {},
   "source": [
    "## üéâ Section 10: Conclusion and Next Steps\n",
    "\n",
    "Congratulations! You've now mastered the fundamentals of embeddings and their role in RAG systems.\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "‚úÖ **Vector Mathematics**: Dot product, cosine similarity, vector spaces\n",
    "‚úÖ **Embedding Concepts**: Converting text to meaningful vectors\n",
    "‚úÖ **TF-IDF vs Neural**: Traditional vs modern embedding methods\n",
    "‚úÖ **Semantic Search**: Finding meaning, not just words\n",
    "‚úÖ **RAG Architecture**: How embeddings power retrieval-augmented generation\n",
    "‚úÖ **Practical Implementation**: Building real systems with embeddings\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Embeddings are vectors that capture meaning** - similar meanings = similar vectors\n",
    "2. **Cosine similarity measures semantic similarity** - perfect for finding related content\n",
    "3. **Neural embeddings understand context** - much better than keyword matching\n",
    "4. **RAG uses embeddings for retrieval** - enabling AI to access knowledge\n",
    "5. **Vector databases store embeddings efficiently** - essential for production systems\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "üöÄ **Build Your Own RAG System**:\n",
    "- Use vector databases like Pinecone or Chroma\n",
    "- Implement semantic search for your documents\n",
    "- Connect to LLMs for answer generation\n",
    "\n",
    "üîß **Explore Advanced Topics**:\n",
    "- Multi-modal embeddings (text + images)\n",
    "- Fine-tuning embedding models\n",
    "- Optimizing for specific domains\n",
    "- Production deployment strategies\n",
    "\n",
    "üìö **Resources**:\n",
    "- [Sentence Transformers Documentation](https://www.sbert.net/)\n",
    "- [Hugging Face Embeddings](https://huggingface.co/models?pipeline_tag=sentence-similarity)\n",
    "- [Vector Database Comparison](https://zilliz.com/comparison)\n",
    "- [RAG Best Practices](https://arxiv.org/abs/2312.10997)\n",
    "\n",
    "### Final Challenge\n",
    "\n",
    "Try building a semantic search system for your own documents or create a RAG chatbot for a specific domain. The concepts you've learned here are the foundation of modern AI applications!\n",
    "\n",
    "---\n",
    "\n",
    "**Happy embedding! üöÄ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Final Challenge: Build Your Own Semantic Search\n",
    "\n",
    "# Your turn! Create a semantic search system for your own content\n",
    "print(\"üéØ Final Challenge: Build Your Own Semantic Search System\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example: Create a knowledge base about your favorite topic\n",
    "my_knowledge_base = [\n",
    "    # Add your own documents here!\n",
    "    \"Your first document about your topic\",\n",
    "    \"Your second document with related information\", \n",
    "    \"Another document that might be relevant\",\n",
    "    # Add more documents...\n",
    "]\n",
    "\n",
    "if len(my_knowledge_base) > 3:  # Only run if you've added content\n",
    "    print(\"üìö Your Knowledge Base:\")\n",
    "    for i, doc in enumerate(my_knowledge_base, 1):\n",
    "        print(f\"{i}. {doc}\")\n",
    "    \n",
    "    # Create embeddings\n",
    "    print(\"\\nüîÑ Creating embeddings...\")\n",
    "    my_embeddings = model.encode(my_knowledge_base)\n",
    "    \n",
    "    # Test your search\n",
    "    my_query = \"Your test query here\"\n",
    "    print(f\"\\nüîç Testing with query: {my_query}\")\n",
    "    \n",
    "    results = semantic_search(my_query, my_embeddings, my_knowledge_base)\n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{i}. Similarity: {result['similarity']:.3f}\")\n",
    "        print(f\"   {result['document']}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"üí° Add your own documents to my_knowledge_base and test your semantic search!\")\n",
    "    print(\"Example topics: cooking recipes, travel guides, technical documentation, etc.\")\n",
    "\n",
    "print(\"\\nüéâ Congratulations on completing the embeddings tutorial!\")\n",
    "print(\"You now have the foundation to build powerful AI applications with RAG!\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
