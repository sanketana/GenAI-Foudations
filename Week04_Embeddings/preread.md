# Week 04: Pre-Reading Materials

## Required Reading
1. **"Understanding Word Embeddings"** - OpenAI Documentation
   - Introduction to embeddings and their properties

2. **"Vector Similarity and Distance Metrics"** 
   - Mathematical foundations of similarity measures

## Recommended Reading
1. **"Word2Vec Explained"** - Original paper concepts simplified
2. **"Sentence Transformers Documentation"**
   - Alternative approaches to text embeddings

## Mathematical Prerequisites
- **Linear Algebra Basics**
  - Vectors and vector operations
  - Dot products and projections
  - Vector normalization

- **Basic Statistics**
  - Correlation and similarity
  - Clustering concepts

## Code Preparation
```python
# Install required libraries
pip install openai
pip install numpy
pip install scikit-learn
pip install matplotlib
pip install plotly
```

## Videos to Watch
1. **"Vector Embeddings Explained"** - 3Blue1Brown (20 minutes)
2. **"Semantic Search with Embeddings"** - OpenAI (35 minutes)

## Practice Exercises
1. Calculate cosine similarity manually
2. Explore word relationships in embedding space
3. Build a simple similarity search
4. Visualize embeddings using plotting libraries

## Key Concepts to Master
- High-dimensional vector spaces
- Semantic vs syntactic similarity
- Embedding quality evaluation
- Computational efficiency considerations

## Preparation Questions
1. How do embeddings capture semantic meaning?
2. What are the limitations of current embedding models?
3. How might embeddings be biased?

## Estimated Reading Time: 3-4 hours 