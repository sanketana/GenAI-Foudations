{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03266fea-f770-4c64-9d85-f8a6db727b41",
   "metadata": {},
   "source": [
    "![RAG Architecture](RAG_Architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4b801e-8c08-43a9-8234-b3bd13aa8e4e",
   "metadata": {},
   "source": [
    "### RAG Components\n",
    "1. Document Loading\n",
    "2. Document Splitting\n",
    "3. Vectorstores and Embedding\n",
    "4. Retrieval\n",
    "5. Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c521c-6c72-4705-9e89-3cf472e0a732",
   "metadata": {},
   "source": [
    "## 1) Loaders\n",
    "In LangChain, a document loader is a utility that helps you load data from different sources into a standardized document format so that it can be processed further (cleaned, split, embedded, retrieved, etc.).\n",
    "\n",
    "#### Examples:\n",
    "1. Text Loader\n",
    "2. CSV Loader\n",
    "3. PDF Loader\n",
    "4. YouTube Loader\n",
    "5. WebBase Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb8aaf4-f562-4136-b898-988d5d3d7010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.13/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./venv/lib/python3.13/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./venv/lib/python3.13/site-packages (from langchain) (0.4.29)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain) (2.11.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain-community in ./venv/lib/python3.13/site-packages (0.3.29)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.3.76)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2.32.5 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.13/site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.4.29)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.3.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./venv/lib/python3.13/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pypdf in ./venv/lib/python3.13/site-packages (6.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install langchain\n",
    "!pip install langchain-community\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0248fd-35cf-421e-8a94-e265221ee3c0",
   "metadata": {},
   "source": [
    "#### PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b9dbc4-5eeb-49ab-9655-eb881fb35952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e32979-26a1-4497-9f0b-2755dd4f2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a0c4a09-6d70-45cf-a3ed-f8d21c903e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffec384e-e1e3-4ddd-aaf2-827a38ad991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pages[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "347f0008-280d-4ff2-9b2c-b83492a5735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='many biologers are there here? Wow, just a few, not many. I'm surprised. Anyone from \n",
      "statistics? Okay, a few. So where are the rest of you from?  \n",
      "Student : iCME.  \n",
      "Instructor (Andrew Ng) : Say again?  \n",
      "Student : iCME.  \n",
      "Instructor (Andrew Ng) : iCME. Cool.  \n",
      "Student : [Inaudible].  \n",
      "Instructor (Andrew Ng) : Civi and what else?  \n",
      "Student : [Inaudible]  \n",
      "Instructor (Andrew Ng) : Synthesis, [inaudible] systems. Yeah, cool.  \n",
      "Student : Chemi.  \n",
      "Instructor (Andrew Ng) : Chemi. Cool.  \n",
      "Student : [Inaudible].  \n",
      "Instructor (Andrew Ng) : Aero/astro. Yes, right. Yeah, okay, cool. Anyone else?  \n",
      "Student : [Inaudible].  \n",
      "Instructor (Andrew Ng) : Pardon? MSNE. All right. Cool. Yeah.  \n",
      "Student : [Inaudible].  \n",
      "Instructor (Andrew Ng) : Pardon?  \n",
      "Student : [Inaudible].  \n",
      "Instructor (Andrew Ng) : Endo —  \n",
      "Student : [Inaudible].  \n",
      "Instructor (Andrew Ng) : Oh, I see, industry. Okay. Cool. Great, great. So as you can \n",
      "tell from a cross-section of this class, I think we're a very diverse audience in this room, \n",
      "and that's one of the things that makes this class fun to teach and fun to be in, I think.' metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': 'MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 1, 'page_label': '2'}\n"
     ]
    }
   ],
   "source": [
    "print(pages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d41972-eeac-4b70-92f1-2ec9689310a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': 'MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 1, 'page_label': '2'}\n"
     ]
    }
   ],
   "source": [
    "print(pages[1].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850d9de-e53f-47a4-a693-ab3f6eb37c55",
   "metadata": {},
   "source": [
    "#### Youtube Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbdcf919-2c9b-497d-856a-2c196fe51e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_yt_dlp in ./venv/lib/python3.13/site-packages (0.0.8)\n",
      "Requirement already satisfied: yt-dlp in ./venv/lib/python3.13/site-packages (from langchain_yt_dlp) (2025.9.5)\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.13/site-packages (from langchain_yt_dlp) (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (0.4.29)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (2.11.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->langchain_yt_dlp) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->langchain_yt_dlp) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->langchain_yt_dlp) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain->langchain_yt_dlp) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain->langchain_yt_dlp) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain->langchain_yt_dlp) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain->langchain_yt_dlp) (2025.8.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain->langchain_yt_dlp) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain->langchain_yt_dlp) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain->langchain_yt_dlp) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain->langchain_yt_dlp) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->langchain_yt_dlp) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->langchain_yt_dlp) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->langchain_yt_dlp) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->langchain_yt_dlp) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "427fd13c-423c-49c5-b76a-1a202da698f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_yt_dlp.youtube_loader import YoutubeLoaderDL\n",
    "\n",
    "# Basic transcript loading\n",
    "loader = YoutubeLoaderDL.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\", add_video_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad293067-11ec-4fbc-a995-3f31783b5283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: [youtube] dQw4w9WgXcQ: Requested format is not available. Use --list-formats for a list of available formats\n"
     ]
    },
    {
     "ename": "DownloadError",
     "evalue": "ERROR: [youtube] dQw4w9WgXcQ: Requested format is not available. Use --list-formats for a list of available formats",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mExtractorError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Sanketana/GenAI-Foundations/Week06_RAG_1/code/venv/lib/python3.13/site-packages/yt_dlp/YoutubeDL.py:1668\u001b[39m, in \u001b[36mYoutubeDL._handle_extraction_exceptions.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1667\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1668\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1669\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (CookieLoadError, DownloadCancelled, LazyList.IndexError, PagedList.IndexError):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Sanketana/GenAI-Foundations/Week06_RAG_1/code/venv/lib/python3.13/site-packages/yt_dlp/YoutubeDL.py:1824\u001b[39m, in \u001b[36mYoutubeDL.__extract_info\u001b[39m\u001b[34m(self, url, ie, download, extra_info, process)\u001b[39m\n\u001b[32m   1823\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_video(ie_result)\n\u001b[32m-> \u001b[39m\u001b[32m1824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_ie_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mie_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1825\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Sanketana/GenAI-Foundations/Week06_RAG_1/code/venv/lib/python3.13/site-packages/yt_dlp/YoutubeDL.py:1883\u001b[39m, in \u001b[36mYoutubeDL.process_ie_result\u001b[39m\u001b[34m(self, ie_result, download, extra_info)\u001b[39m\n\u001b[32m   1882\u001b[39m \u001b[38;5;28mself\u001b[39m.add_extra_info(ie_result, extra_info)\n\u001b[32m-> \u001b[39m\u001b[32m1883\u001b[39m ie_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_video_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mie_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[38;5;28mself\u001b[39m._raise_pending_errors(ie_result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Sanketana/GenAI-Foundations/Week06_RAG_1/code/venv/lib/python3.13/site-packages/yt_dlp/YoutubeDL.py:3027\u001b[39m, in \u001b[36mYoutubeDL.process_video_result\u001b[39m\u001b[34m(self, info_dict, download)\u001b[39m\n\u001b[32m   3026\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.params.get(\u001b[33m'\u001b[39m\u001b[33mignore_no_formats_error\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m3027\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ExtractorError(\n\u001b[32m   3028\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mRequested format is not available. Use --list-formats for a list of available formats\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   3029\u001b[39m         expected=\u001b[38;5;28;01mTrue\u001b[39;00m, video_id=info_dict[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m], ie=info_dict[\u001b[33m'\u001b[39m\u001b[33mextractor\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m   3030\u001b[39m \u001b[38;5;28mself\u001b[39m.report_warning(\u001b[33m'\u001b[39m\u001b[33mRequested format is not available\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mExtractorError\u001b[39m: [youtube] dQw4w9WgXcQ: Requested format is not available. Use --list-formats for a list of available formats",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mDownloadError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m documents = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Sanketana/GenAI-Foundations/Week06_RAG_1/code/venv/lib/python3.13/site-packages/langchain_yt_dlp/youtube_loader.py:41\u001b[39m, in \u001b[36mYoutubeLoaderDL.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load YouTube transcripts into 'Document' objects.\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.add_video_info:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     video_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_video_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28mself\u001b[39m._metadata.update(video_info)\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [Document(page_content=\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m,metadata=\u001b[38;5;28mself\u001b[39m._metadata)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Sanketana/GenAI-Foundations/Week06_RAG_1/code/venv/lib/python3.13/site-packages/langchain_yt_dlp/youtube_loader.py:68\u001b[39m, in \u001b[36mYoutubeLoaderDL._get_video_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     66\u001b[39m ydl_opts = {\u001b[33m\"\u001b[39m\u001b[33mquiet\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mno_warnings\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mskip_download\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m YoutubeDL(ydl_opts) \u001b[38;5;28;01mas\u001b[39;00m ydl:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     yt = \u001b[43mydl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://www.youtube.com/watch?v=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvideo_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     publish_date = yt.get(\u001b[33m\"\u001b[39m\u001b[33mupload_date\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m publish_date:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Sanketana/GenAI-Foundations/Week06_RAG_1/code/venv/lib/python3.13/site-packages/yt_dlp/YoutubeDL.py:1657\u001b[39m, in \u001b[36mYoutubeDL.extract_info\u001b[39m\u001b[34m(self, url, download, ie_key, extra_info, process, force_generic_extractor)\u001b[39m\n\u001b[32m   1655\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ExistingVideoReached\n\u001b[32m   1656\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__extract_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_info_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1659\u001b[39m     extractors_restricted = \u001b[38;5;28mself\u001b[39m.params.get(\u001b[33m'\u001b[39m\u001b[33mallowed_extractors\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, [\u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Sanketana/GenAI-Foundations/Week06_RAG_1/code/venv/lib/python3.13/site-packages/yt_dlp/YoutubeDL.py:1686\u001b[39m, in \u001b[36mYoutubeDL._handle_extraction_exceptions.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1684\u001b[39m     \u001b[38;5;28mself\u001b[39m.report_error(msg)\n\u001b[32m   1685\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ExtractorError \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# An error we somewhat expected\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1686\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreport_error\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.params.get(\u001b[33m'\u001b[39m\u001b[33mignoreerrors\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Sanketana/GenAI-Foundations/Week06_RAG_1/code/venv/lib/python3.13/site-packages/yt_dlp/YoutubeDL.py:1126\u001b[39m, in \u001b[36mYoutubeDL.report_error\u001b[39m\u001b[34m(self, message, *args, **kwargs)\u001b[39m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreport_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, message, *args, **kwargs):\n\u001b[32m   1122\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1123\u001b[39m \u001b[33;03m    Do the same as trouble, but prefixes the message with 'ERROR:', colored\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[33;03m    in red if stderr is a tty file.\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1126\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrouble\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_err\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mERROR:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mStyles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mERROR\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmessage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Sanketana/GenAI-Foundations/Week06_RAG_1/code/venv/lib/python3.13/site-packages/yt_dlp/YoutubeDL.py:1065\u001b[39m, in \u001b[36mYoutubeDL.trouble\u001b[39m\u001b[34m(self, message, tb, is_error)\u001b[39m\n\u001b[32m   1063\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1064\u001b[39m         exc_info = sys.exc_info()\n\u001b[32m-> \u001b[39m\u001b[32m1065\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DownloadError(message, exc_info)\n\u001b[32m   1066\u001b[39m \u001b[38;5;28mself\u001b[39m._download_retcode = \u001b[32m1\u001b[39m\n",
      "\u001b[31mDownloadError\u001b[39m: ERROR: [youtube] dQw4w9WgXcQ: Requested format is not available. Use --list-formats for a list of available formats"
     ]
    }
   ],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743a8ca-dfb5-4115-bda6-00a0281a4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965d904a-d987-4936-a87b-96620fbd7373",
   "metadata": {},
   "source": [
    "#### WebBase Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba9dd5ed-9132-4b69-acfe-e2e7c6f48ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://github.com/sanketana/GenAI-Foudations/blob/main/Week06_RAG_1/notes.md\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7873953e-d1b7-428c-9b59-8ff524e62a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GenAI-Foudations/Week06_RAG_1/notes.md at main · sanketana/GenAI-Foudations · GitHub\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Navigation Menu\n",
      "\n",
      "Toggle navigation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Sign in\n",
      "          \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Appearance settings\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Platform\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          GitHub Copilot\n",
      "\n",
      "        \n",
      "\n",
      "        Write better code with AI\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          GitHub Spark\n",
      "\n",
      "            \n",
      "              New\n",
      "            \n",
      "\n",
      "\n",
      "        Build and deploy intelligent apps\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          GitHub Models\n",
      "\n",
      "            \n",
      "              New\n",
      "            \n",
      "\n",
      "\n",
      "        Manage and compare prompts\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          GitHub Advanced Security\n",
      "\n",
      "        \n",
      "\n",
      "        Find and fix vulnerabilities\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Actions\n",
      "\n",
      "        \n",
      "\n",
      "        Automate any workflow\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Codespaces\n",
      "\n",
      "        \n",
      "\n",
      "        Instant dev environments\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Issues\n",
      "\n",
      "        \n",
      "\n",
      "        Plan and track work\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Code Review\n",
      "\n",
      "        \n",
      "\n",
      "        Manage code changes\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Discussions\n",
      "\n",
      "        \n",
      "\n",
      "        Collaborate outside of code\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Code Search\n",
      "\n",
      "        \n",
      "\n",
      "        Find more, search less\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Explore\n",
      "\n",
      "\n",
      "\n",
      "      Why GitHub\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Documentation\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      GitHub Skills\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Blog\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Integrations\n",
      "\n",
      "\n",
      "\n",
      "      GitHub Marketplace\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      MCP Registry\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              View all features\n",
      "              \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Solutions\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "By company size\n",
      "\n",
      "\n",
      "\n",
      "      Enterprises\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Small and medium teams\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Startups\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Nonprofits\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "By use case\n",
      "\n",
      "\n",
      "\n",
      "      App Modernization\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      DevSecOps\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      DevOps\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      CI/CD\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      View all use cases\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "By industry\n",
      "\n",
      "\n",
      "\n",
      "      Healthcare\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Financial services\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Manufacturing\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Government\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      View all industries\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              View all solutions\n",
      "              \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Resources\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Topics\n",
      "\n",
      "\n",
      "\n",
      "      AI\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      DevOps\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Security\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Software Development\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      View all\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Explore\n",
      "\n",
      "\n",
      "\n",
      "      Learning Pathways\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Events & Webinars\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Ebooks & Whitepapers\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Customer Stories\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Partners\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Executive Insights\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Open Source\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          GitHub Sponsors\n",
      "\n",
      "        \n",
      "\n",
      "        Fund open source developers\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          The ReadME Project\n",
      "\n",
      "        \n",
      "\n",
      "        GitHub community articles\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Repositories\n",
      "\n",
      "\n",
      "\n",
      "      Topics\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Trending\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "      Collections\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Enterprise\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Enterprise platform\n",
      "\n",
      "        \n",
      "\n",
      "        AI-powered developer platform\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Available add-ons\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          GitHub Advanced Security\n",
      "\n",
      "        \n",
      "\n",
      "        Enterprise-grade security features\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Copilot for business\n",
      "\n",
      "        \n",
      "\n",
      "        Enterprise-grade AI features\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Premium Support\n",
      "\n",
      "        \n",
      "\n",
      "        Enterprise-grade 24/7 support\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Pricing\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search or jump to...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search code, repositories, users, issues, pull requests...\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Search\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Clear\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Search syntax tips \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Provide feedback\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "We read every piece of feedback, and take your input very seriously.\n",
      "\n",
      "\n",
      "Include my email address so I can be contacted\n",
      "\n",
      "\n",
      "     Cancel\n",
      "\n",
      "    Submit feedback\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Saved searches\n",
      "      \n",
      "Use saved searches to filter your results more quickly\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Name\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Query\n",
      "\n",
      "\n",
      "\n",
      "            To see all available qualifiers, see our documentation.\n",
      "          \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     Cancel\n",
      "\n",
      "    Create saved search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                Sign in\n",
      "              \n",
      "\n",
      "\n",
      "                Sign up\n",
      "              \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Appearance settings\n",
      "\n",
      "\n",
      "\n",
      "Resetting focus\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You signed in with another tab or window. Reload to refresh your session.\n",
      "You signed out in another tab or window. Reload to refresh your session.\n",
      "You switched accounts on another tab or window. Reload to refresh your session.\n",
      " \n",
      "\n",
      "\n",
      "Dismiss alert\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        sanketana\n",
      " \n",
      "/\n",
      "\n",
      "GenAI-Foudations\n",
      "\n",
      "Public\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Notifications\n",
      " You must be signed in to change notification settings\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Fork\n",
      "    0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "          Star\n",
      " 2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Code\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Issues\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Pull requests\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Actions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Projects\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Security\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        Uh oh!\n",
      "\n",
      " There was an error while loading. Please reload this page.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Insights\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "Additional navigation options\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Code\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Issues\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Pull requests\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Actions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Projects\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Security\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Insights\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Footer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        © 2025 GitHub, Inc.\n",
      "      \n",
      "\n",
      "\n",
      "Footer navigation\n",
      "\n",
      "\n",
      "Terms\n",
      "\n",
      "\n",
      "Privacy\n",
      "\n",
      "\n",
      "Security\n",
      "\n",
      "\n",
      "Status\n",
      "\n",
      "\n",
      "Community\n",
      "\n",
      "\n",
      "Docs\n",
      "\n",
      "\n",
      "Contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "       Manage cookies\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Do not share my personal information\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    You can’t perform that action at this time.\n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "' metadata={'source': 'https://github.com/sanketana/GenAI-Foudations/blob/main/Week06_RAG_1/notes.md', 'title': 'GenAI-Foudations/Week06_RAG_1/notes.md at main · sanketana/GenAI-Foudations · GitHub', 'description': 'Contribute to sanketana/GenAI-Foudations development by creating an account on GitHub.', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86cf56e-8c5d-4953-bec7-35f3e2b61461",
   "metadata": {},
   "source": [
    "## 2) Splitters\n",
    "A document splitter is a utility that takes a large document (or multiple documents) and breaks it into smaller, more manageable chunks of text.\n",
    "\n",
    "#### Types of Splitters in Langchain\n",
    "1. CharacterTextSplitter\n",
    "2. RecursiveCharacterTextSplitter\n",
    "3. TokenTextSplitter\n",
    "4. Markdown / Code Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cbde72-1767-4e4b-8c16-a4812de9800d",
   "metadata": {},
   "source": [
    "![Example Splitter](Example_Splitter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c19ed-b3d7-4765-a428-797b04916038",
   "metadata": {},
   "source": [
    "| Feature                  | CharacterTextSplitter                        | RecursiveCharacterTextSplitter                          |\n",
    "|---------------------------|-----------------------------------------------|---------------------------------------------------------|\n",
    "| Splitting method          | Fixed-size, raw character cuts               | Tries hierarchical separators (para → sentence → word → char) |\n",
    "| Preserves semantic meaning| ❌ Often cuts in middle of words/sentences    | ✅ Keeps chunks aligned to natural text boundaries       |\n",
    "| Default separators        | [\"\\n\\n\"]                       | `[\"\\n\\n\", \"\\n\", \" \", \"\"]` (paragraph, line, space, char)|\n",
    "| Chunk size handling       | Strict cutoff at `chunk_size`                | Tries largest separator where chunk ≤ `chunk_size`      |\n",
    "| Chunk overlap             | ✅ Supported                                 | ✅ Supported                                            |\n",
    "| Output consistency        | More predictable (always equal-sized chunks) | More variable (chunks may differ in size depending on separators) |\n",
    "| Performance               | Faster, simpler                             | Slightly slower due to recursive splitting logic        |\n",
    "| Readability of chunks     | Poor (fragments of sentences)                 | Better (complete sentences/paragraphs where possible)   |\n",
    "| Best use case             | Very short/simple text; testing              | Long docs, PDFs, transcripts, RAG pipelines             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee149179-a12e-4768-8953-1f3989d4b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d7d19af-5a03-433f-810b-7579f5f6361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "text = \"\"\"Artificial Intelligence is changing the world. It is being used in healthcare, education, and entertainment. \n",
    "\n",
    "However, AI also raises ethical concerns. Bias, privacy, and misuse are important issues.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06ca606a-1a82-42b7-81e8-7ebfda3507a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =50\n",
    "chunk_overlap = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e581f70e-5517-42a6-a9ab-0230c5925856",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8281d76f-1331-4dec-a4ee-00e218e821e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 109, which is longer than the specified 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial Intelligence is changing the world. It is being used in healthcare, education, and entertainment.', 'However, AI also raises ethical concerns. Bias, privacy, and misuse are important issues.']\n"
     ]
    }
   ],
   "source": [
    "char_chunks = c_splitter.split_text(text)\n",
    "print(char_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "370e3821-400e-4c52-8cd8-d8bda1730b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is changing the world. It is being used in healthcare, education, and entertainment.\n",
      "However, AI also raises ethical concerns. Bias, privacy, and misuse are important issues.\n"
     ]
    }
   ],
   "source": [
    "for chunk in char_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3294c600-76c3-45d5-b165-c7be981e7295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial Intelligence is changing the world. It', 'world. It is being used in healthcare, education,', 'and entertainment.', 'However, AI also raises ethical concerns. Bias,', 'Bias, privacy, and misuse are important issues.']\n"
     ]
    }
   ],
   "source": [
    "rec_chunks = r_splitter.split_text(text)\n",
    "print(rec_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "295ddab3-dec7-4d6e-91c7-9f2dc49311a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is changing the world. It\n",
      "world. It is being used in healthcare, education,\n",
      "and entertainment.\n",
      "However, AI also raises ethical concerns. Bias,\n",
      "Bias, privacy, and misuse are important issues.\n"
     ]
    }
   ],
   "source": [
    "for chunk in rec_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4b137-4463-4a68-94d7-7eba9ebf3807",
   "metadata": {},
   "source": [
    "## 3) Vectorstores and Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f13bf92-49f1-4a20-afe4-021bbbce17b1",
   "metadata": {},
   "source": [
    "#### Combining loading and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f05fd2-6d82-4706-ab2f-d9106257e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")\n",
    "docs = loader.load()\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e20a8a3b-e667-422e-ae50-b6ef1321de03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
      " 'creator': 'PScript5.dll Version 5.2.2',\n",
      " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
      " 'author': '',\n",
      " 'moddate': '2008-07-11T11:25:23-07:00',\n",
      " 'title': '',\n",
      " 'source': 'MachineLearning-Lecture01.pdf',\n",
      " 'total_pages': 22,\n",
      " 'page': 0,\n",
      " 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pp(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fef243e2-2f05-46a3-bc4f-9a6d3948b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulk Loading PDF\n",
    "loaders = [\n",
    "    PyPDFLoader(\"MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture02.pdf\"),    \n",
    "    PyPDFLoader(\"MachineLearning-Lecture03.pdf\"),    \n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5d1e2f9-cfda-43df-8e59-d03bd928b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d65be5f-ef62-41d9-93e8-6658f4eb66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5bba6c7-2177-4053-97ca-d779acd8c52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "print(len(splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f701e8b5-d20d-48c1-a81c-50258fd81cc1",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d89a8-2c51-431f-b481-907a424b6b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-openai\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da0f59b1-53c2-4a6d-b879-69f6e15b51c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: sk-pr*****\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access your API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"API Key:\", api_key[:5] + \"*****\")  # just to verify it’s loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78a2ab6b-98af-4ce7-a0db-c0458c58f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "# Can also explicitly pass key as openai_api_key=api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8155fb09-4ee0-4476-b894-71709c0a9df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee1 = \"I enjoy drinking coffee in the morning.\"\n",
    "coffee2 = \"I love having a cup of filter coffee when I wake up\"\n",
    "market = \"The stock market had a big crash yesterday.\"\n",
    "mug = \"I crashed the stock of my coffee mug yesterday.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adc1ea09-0d23-415a-b3cb-fd1417195a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee1_embedding = embedding.embed_query(coffee1)\n",
    "coffee2_embedding = embedding.embed_query(coffee2)\n",
    "market_embedding = embedding.embed_query(market)\n",
    "mug_embedding = embedding.embed_query(mug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5d129d1-19ab-4a41-80d6-6a296314caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f4a0652-c819-4ec8-b94f-7f3e7b35d48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.627351559087536)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array(coffee1_embedding), np.array(coffee2_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f570a395-bb0b-486f-b5b5-806801c21497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.07100796107510074)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array(coffee1_embedding), np.array(market_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad38d47-cd9e-4c9c-bbe0-8603c6c5225a",
   "metadata": {},
   "source": [
    "### Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050ae3d-f672-479c-9dbe-1df1d0ed7fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32ad48c7-8d76-4db1-99cb-7a4973b184e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "891c5846-9d52-4911-afed-ff4002b23605",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma'\n",
    "!rm -rf ./docs/chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c2d3ae0-8632-4215-909c-853e94690432",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c503c5fd-03b0-4687-99de-21721204cec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b148ccc6-04a2-4969-86c1-53e7841f7a26",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48124048-b48d-4299-aa94-64269aadad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email i can ask for help\"\n",
    "docs = vectordb.similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66ce59a2-1924-45cd-b72b-058f9c79ea00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a67a165e-a146-4cb9-9cf1-4b3a5d4c8e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cs229-qa@cs.stanford.edu. This goes to an account that's read by all the TAs and me. So \\nrather than sending us email individually, if you send email to this account, it will \\nactually let us get back to you maximally quickly with answers to your questions.  \\nIf you're asking questions about homework problems, please say in the subject line which \\nassignment and which question the email refers to, since that will also help us to route \\nyour question to the appropriate TA or to me appropriately and get the response back to \\nyou quickly.  \\nLet's see. Skipping ahead — let's see — for homework, one midterm, one open and term \\nproject. Notice on the honor code. So one thing that I think will help you to succeed and \\ndo well in this class and even help you to enjoy this class more is if you form a study \\ngroup.  \\nSo start looking around where you're sitting now or at the end of class today, mingle a \\nlittle bit and get to know your classmates. I strongly encourage you to form study groups \\nand sort of have a group of people to study with and have a group of your fellow students \\nto talk over these concepts with. You can also post on the class newsgroup if you want to \\nuse that to try to form a study group.  \\nBut some of the problems sets in this class are reasonably difficult. People that have \\ntaken the class before may tell you they were very difficult. And just I bet it would be \\nmore fun for you, and you'd probably have a better learning experience if you form a\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bf20f-2f0e-418d-8158-ee6aadf12251",
   "metadata": {},
   "source": [
    "### Failure Cases - Duplicate Chunks in Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a8210f9-bba3-4f6e-bc3c-1adf5d68f850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'moddate': '2008-07-11T11:25:23-07:00', 'page': 8, 'total_pages': 22, 'title': '', 'page_label': '9', 'creator': 'PScript5.dll Version 5.2.2', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'author': '', 'source': 'MachineLearning-Lecture01.pdf', 'creationdate': '2008-07-11T11:25:23-07:00'}, page_content='those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it\\'s free, and for the purposes of this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine learning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, like, ten years ago came \\ninto his office and he said, \"Oh, professor, professor, thank you so much for your')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about the matlab\"\n",
    "docs = vectordb.similarity_search(question, k=5)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6473a39-dae9-4331-b811-9fd3f1c520f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'author': '', 'source': 'MachineLearning-Lecture01.pdf', 'moddate': '2008-07-11T11:25:23-07:00', 'creator': 'PScript5.dll Version 5.2.2', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'total_pages': 22, 'creationdate': '2008-07-11T11:25:23-07:00', 'page': 8, 'title': '', 'page_label': '9'}, page_content='those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it\\'s free, and for the purposes of this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine learning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, like, ten years ago came \\ninto his office and he said, \"Oh, professor, professor, thank you so much for your')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a2234-e443-4caf-a875-95ea9df176ed",
   "metadata": {},
   "source": [
    "### Failure Cases - Semantic Lookup ignoring Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12f6cce0-96f9-41b3-af79-4fd8dee6ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'moddate': '2008-07-11T11:25:03-07:00', 'page': 0, 'creator': 'PScript5.dll Version 5.2.2', 'page_label': '1', 'total_pages': 16, 'source': 'MachineLearning-Lecture03.pdf', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'author': '', 'title': '', 'creationdate': '2008-07-11T11:25:03-07:00'}\n",
      "{'page': 14, 'page_label': '15', 'title': '', 'total_pages': 16, 'creationdate': '2008-07-11T11:25:03-07:00', 'author': '', 'moddate': '2008-07-11T11:25:03-07:00', 'source': 'MachineLearning-Lecture03.pdf', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2'}\n",
      "{'creator': 'PScript5.dll Version 5.2.2', 'page_label': '7', 'title': '', 'page': 6, 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'source': 'MachineLearning-Lecture03.pdf', 'moddate': '2008-07-11T11:25:03-07:00', 'total_pages': 16, 'creationdate': '2008-07-11T11:25:03-07:00', 'author': ''}\n",
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'page': 2, 'creationdate': '2008-07-11T11:25:03-07:00', 'author': '', 'moddate': '2008-07-11T11:25:03-07:00', 'total_pages': 16, 'title': '', 'source': 'MachineLearning-Lecture03.pdf', 'creator': 'PScript5.dll Version 5.2.2', 'page_label': '3'}\n",
      "{'creationdate': '2008-07-11T11:25:05-07:00', 'page_label': '1', 'page': 0, 'creator': 'PScript5.dll Version 5.2.2', 'author': '', 'title': '', 'source': 'MachineLearning-Lecture02.pdf', 'total_pages': 18, 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'moddate': '2008-07-11T11:25:05-07:00'}\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about regression in the third lecture\"\n",
    "docs = vectordb.similarity_search(question, k=5)\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5622377-0e35-4542-a87f-c6cbd85a2b77",
   "metadata": {},
   "source": [
    "## 4) Retrieval\n",
    "Fetching the most relevant pieces of external information (chunks of documents, knowledge base, etc.) to provide extra context to the LLM before it generates an answer.\n",
    "\n",
    "#### Types of Retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c17bf5c-736b-497b-9060-c596b3c0d7d4",
   "metadata": {},
   "source": [
    "| Attribute            | Vector Similarity                          | BM25 / Keyword                  | Hybrid Search                     | Re-ranking                          | Structured Retrieval                  |\n",
    "|----------------------|-------------------------------------------|---------------------------------|----------------------------------|------------------------------------|--------------------------------------|\n",
    "| How It Works          | Embed query & docs, find nearest vectors | TF-IDF based keyword match       | Combines vector + keyword search  | Retrieve many, rerank with model   | Query structured DB or API            |\n",
    "| Strengths             | Captures semantic meaning                 | Exact keyword matching           | Balances semantic & lexical      | High precision ranking             | Accurate for structured facts         |\n",
    "| Weaknesses            | Misses exact keywords                     | Fails on semantic similarity     | More complex infra               | Expensive at scale                  | Needs schema alignment                |\n",
    "| When to Use           | General semantic search                   | Legal, technical, IDs           | Production-grade RAG             | Customer-facing apps, high accuracy | Enterprise + DB + knowledge graph    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d89345-3124-4281-bb9d-9d0186ca440d",
   "metadata": {},
   "source": [
    "#### Maximum Marginal Relevance (MMR)\n",
    "- You may not always want to choose the most similar responses\n",
    "- Could give a very narrow view of the topic\n",
    "- Eg:\n",
    "1. **Wikipedia / Photosynthesis**  \n",
    "   - **Without MMR**: Top-k retrieves 3 paragraphs all about the light reaction.  \n",
    "   - **With MMR**: You get **light reaction + Calvin cycle + chloroplast structure** — comprehensive and non-repetitive.  \n",
    "\n",
    "2. **News Articles / Election Results**  \n",
    "   - **Without MMR**: Top-k might select 3 snippets all repeating **who won**.  \n",
    "   - **With MMR**: You get **winner + voter turnout + reactions from parties and citizens** — broader context.  \n",
    "\n",
    "3. **Product Reviews / Smartphone Pros**  \n",
    "   - **Without MMR**: Top-k selects 3 reviews all saying **camera is good**.  \n",
    "   - **With MMR**: You get **camera + battery + display quality** — highlights diverse advantages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c3cae18-1649-4d5d-8af4-ade6f0ec7947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people c'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)\n",
    "docs_ss[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12f91037-e0d3-492e-9b26-a6619357a8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people c'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "793285aa-36d7-45e8-8e03-5358a21268e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people c'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)\n",
    "docs_mmr[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ed38734-88ee-4bc7-b47c-2368d543e801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'least squares regression being a bad idea for classification problems and then I did a \\nbunch of mat'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9594d80d-fb48-4e4c-a9d5-31d9a1b7bb2b",
   "metadata": {},
   "source": [
    "#### Metadata Based Search\n",
    "Augumenting similarity search with exact metadata wherever possible\n",
    "Eg: Search for regression in 3rd lecture transcript which is MachineLearning-Lecture03.pdf (metadata filer Source: MachineLearning-Lecture03.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "587cf2c3-e882-4f62-bdcb-80cc6a4fba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\"\n",
    "\n",
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"MachineLearning-Lecture03.pdf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca8384e8-1b6e-4ae2-8eab-ddf8cd9b7d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '', 'source': 'MachineLearning-Lecture03.pdf', 'page_label': '1', 'author': '', 'moddate': '2008-07-11T11:25:03-07:00', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'total_pages': 16, 'creationdate': '2008-07-11T11:25:03-07:00', 'creator': 'PScript5.dll Version 5.2.2', 'page': 0}\n",
      "{'moddate': '2008-07-11T11:25:03-07:00', 'creationdate': '2008-07-11T11:25:03-07:00', 'creator': 'PScript5.dll Version 5.2.2', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'total_pages': 16, 'page': 14, 'title': '', 'source': 'MachineLearning-Lecture03.pdf', 'author': '', 'page_label': '15'}\n",
      "{'moddate': '2008-07-11T11:25:03-07:00', 'page': 6, 'creationdate': '2008-07-11T11:25:03-07:00', 'creator': 'PScript5.dll Version 5.2.2', 'page_label': '7', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'title': '', 'total_pages': 16, 'author': '', 'source': 'MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a35ce-3a5f-429e-be9c-dd2ed5941faa",
   "metadata": {},
   "source": [
    "#### Metadata Self Query Retriever\n",
    "\n",
    "SelfQueryRetriever uses an LLM to dynamically translate your natural language question into both semantic + metadata queries so that your vector DB returns the most relevant and context-aware chunks.\n",
    "\n",
    "##### What it does internally:\n",
    "- Determines semantic intent\n",
    "- Determines metadata filters if applicable\n",
    "- Sends the query to vector DB with filters\n",
    "\n",
    "##### Why this is powerful\n",
    "- You don’t need to manually write filters or craft queries.\n",
    "- The LLM automatically “understands” the schema and selects relevant docs.\n",
    "- Works well for RAG pipelines, especially with metadata-rich corpora (like CS229 transcripts with topics, lecture numbers, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b73cf61-5ec0-42dc-9341-2b1be4e3c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "727fffd2-ed57-4047-b887-cdd07eafbb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of `MachineLearning-Lecture01.pdf`, `MachineLearning-Lecture02.pdf`, or `MachineLearning-Lecture03.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78ae6d0a-7365-4f90-ba7d-3718da5e107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a0eb394-14be-4d3a-be8c-ea985b869b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2874953-6298-4ef7-905c-b50df73d44a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da4414ed-5b84-421d-ba8e-b6bb83fe2136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'moddate': '2008-07-11T11:25:03-07:00', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'title': '', 'page_label': '3', 'source': 'MachineLearning-Lecture03.pdf', 'total_pages': 16, 'creationdate': '2008-07-11T11:25:03-07:00', 'creator': 'PScript5.dll Version 5.2.2', 'page': 2, 'author': ''}\n",
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'source': 'MachineLearning-Lecture03.pdf', 'page': 10, 'moddate': '2008-07-11T11:25:03-07:00', 'title': '', 'total_pages': 16, 'creator': 'PScript5.dll Version 5.2.2', 'author': '', 'page_label': '11', 'creationdate': '2008-07-11T11:25:03-07:00'}\n",
      "{'author': '', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'total_pages': 16, 'page_label': '12', 'moddate': '2008-07-11T11:25:03-07:00', 'title': '', 'creationdate': '2008-07-11T11:25:03-07:00', 'source': 'MachineLearning-Lecture03.pdf', 'creator': 'PScript5.dll Version 5.2.2', 'page': 11}\n",
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'total_pages': 16, 'author': '', 'creationdate': '2008-07-11T11:25:03-07:00', 'source': 'MachineLearning-Lecture03.pdf', 'moddate': '2008-07-11T11:25:03-07:00', 'page_label': '7', 'page': 6, 'title': '', 'creator': 'PScript5.dll Version 5.2.2'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd9b25-5ace-4eff-b539-e4e001ddc1f3",
   "metadata": {},
   "source": [
    "##### RetrievalQA Chain\n",
    "##### Prompt Template\n",
    "##### RetrievalQA Chain types\n",
    "##### Memory\n",
    "##### ConversationalBufferMemory\n",
    "##### ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0fdca4-3a9c-4ab2-92fa-658d82f4e2f6",
   "metadata": {},
   "source": [
    "## 5) Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55960e70-dd4a-454e-921c-db222b1fce53",
   "metadata": {},
   "source": [
    "![RAG Question Answering](RAG_Question_Answering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daea52bb-aa13-486c-8fe7-bbe50e0d7373",
   "metadata": {},
   "source": [
    "![RAG_RetrievalQA_chain](RAG_RetrievalQA_chain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b624f818-aa8b-475a-a024-d59746893168",
   "metadata": {},
   "source": [
    "#### RetrievalQA Methods\n",
    "1. Stuff\n",
    "2. Map Reduce\n",
    "3. Refine\n",
    "4. Map Rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7bb6a1-3b8a-48f7-a538-cadeacae88a6",
   "metadata": {},
   "source": [
    "![RAG_RetrievalQA_methods](RAG_RetrievalQA_methods.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8d9fc28-27b3-4ba9-a0e6-d939b871aa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAI\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c263e9aa-4edf-4b18-9f93-6fba10061b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h_/_l7_dhxd33z3dgrhs7gh3z480000gn/T/ipykernel_34977/3017790310.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma'\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33a93f10-0a78-483f-a754-30dcdc016e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13e70c76-a348-4990-9cf4-62ecf217375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "153a4c96-674e-48b8-8976-831862a5baca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f06c11d-bf10-4bae-b901-397f57f2b3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the content about', 'result': 'The content provides information about the online resources and communication methods for a class, likely a computer science course (CS229) at Stanford University. It mentions the course homepage (http://cs229.stanford.edu) where homework assignments, solutions, and detailed lecture notes are posted. It also discusses a class newsgroup (su.class.cs229) for student discussions and forming study groups, which is not monitored by the teaching staff. For contacting the teaching staff, students are advised to use the email address cs229-qa@cs.stanford.edu. The content also encourages forming study groups to tackle difficult problem sets and enhance the learning experience.'}\n"
     ]
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "question = \"What is the content about\"\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34923918-af11-4269-9526-e38140d176cd",
   "metadata": {},
   "source": [
    "#### Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c58fa2-3173-48fa-8324-260836c369d3",
   "metadata": {},
   "source": [
    "#### RetrievalQA to LCEL Upgrade in Langchain\n",
    "LCEL = Langchain Expression Language\n",
    "- LCEL stands for LangChain Expression Language.\n",
    "- It is a declarative layer (or DSL-style syntax) for orchestrating LangChain “chains” (i.e. compositions of prompts, models, transformations, etc.)\n",
    "- The idea is: instead of manually wiring chain steps with imperative code, you declare what you want with composable “runnables” and use operators (like the pipe |) to define the flow.\n",
    "- Under the hood, components in LCEL are built upon a Runnable interface — every step is a Runnable (or composed of Runnables) that supports invoke, batch, stream, etc.\n",
    "\n",
    "https://python.langchain.com/docs/versions/migrating_chains/retrieval_qa/\n",
    "\n",
    "https://lilianweng.github.io/posts/2023-06-23-agent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c6647f-821e-46cd-8303-6d9462d3e255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
