{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03266fea-f770-4c64-9d85-f8a6db727b41",
   "metadata": {},
   "source": [
    "![RAG Architecture](RAG_Architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4b801e-8c08-43a9-8234-b3bd13aa8e4e",
   "metadata": {},
   "source": [
    "### RAG Components\n",
    "1. Document Loading\n",
    "2. Document Splitting\n",
    "3. Vectorstores and Embedding\n",
    "4. Retrieval\n",
    "5. Question Answering Chain\n",
    "6. Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c521c-6c72-4705-9e89-3cf472e0a732",
   "metadata": {},
   "source": [
    "## 1) Loaders\n",
    "In LangChain, a document loader is a utility that helps you load data from different sources into a standardized document format so that it can be processed further (cleaned, split, embedded, retrieved, etc.).\n",
    "\n",
    "#### Examples:\n",
    "1. Text Loader\n",
    "2. CSV Loader\n",
    "3. PDF Loader\n",
    "4. YouTube Loader\n",
    "5. WebBase Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afb8aaf4-f562-4136-b898-988d5d3d7010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -qU langchain\n",
    "!pip install -qU langchain-community\n",
    "!pip install -qU pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0248fd-35cf-421e-8a94-e265221ee3c0",
   "metadata": {},
   "source": [
    "#### PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36b9dbc4-5eeb-49ab-9655-eb881fb35952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84e32979-26a1-4497-9f0b-2755dd4f2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a0c4a09-6d70-45cf-a3ed-f8d21c903e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffec384e-e1e3-4ddd-aaf2-827a38ad991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pages[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "347f0008-280d-4ff2-9b2c-b83492a5735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='many biologers are there here? Wow, just a few, not many. I'm surprised. Anyone from \n",
      "statistics? Okay, a few. So where are the rest of you from?  \n",
      "Student : iCME.  \n",
      "Instructor (Andrew Ng) : Say again?  \n",
      "Student : iCME.  \n",
      "Instructor (Andrew Ng) : iCME. Cool.  \n",
      "Student : [Inaudible].  \n",
      "Instructor (Andrew Ng) : Civi and what else?  \n",
      "Student : [Inaudible]  \n",
      "Instructor (Andrew Ng) : Synthesis, [inaudible] systems. Yeah, cool.  \n",
      "Student : Chemi.  \n",
      "Instructor (Andrew Ng) : Chemi. Cool.  \n",
      "Student : [Inaudible].  \n",
      "Instructor (Andrew Ng) : Aero/astro. Yes, right. Yeah, okay, cool. Anyone else?  \n",
      "Student : [Inaudible].  \n",
      "Instructor (Andrew Ng) : Pardon? MSNE. All right. Cool. Yeah.  \n",
      "Student : [Inaudible].  \n",
      "Instructor (Andrew Ng) : Pardon?  \n",
      "Student : [Inaudible].  \n",
      "Instructor (Andrew Ng) : Endo —  \n",
      "Student : [Inaudible].  \n",
      "Instructor (Andrew Ng) : Oh, I see, industry. Okay. Cool. Great, great. So as you can \n",
      "tell from a cross-section of this class, I think we're a very diverse audience in this room, \n",
      "and that's one of the things that makes this class fun to teach and fun to be in, I think.' metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': 'MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 1, 'page_label': '2'}\n"
     ]
    }
   ],
   "source": [
    "print(pages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93d41972-eeac-4b70-92f1-2ec9689310a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': 'MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 1, 'page_label': '2'}\n"
     ]
    }
   ],
   "source": [
    "print(pages[1].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850d9de-e53f-47a4-a693-ab3f6eb37c55",
   "metadata": {},
   "source": [
    "#### Youtube Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbdcf919-2c9b-497d-856a-2c196fe51e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "427fd13c-423c-49c5-b76a-1a202da698f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_yt_dlp.youtube_loader import YoutubeLoaderDL\n",
    "\n",
    "# Basic transcript loading\n",
    "loader = YoutubeLoaderDL.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\", add_video_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad293067-11ec-4fbc-a995-3f31783b5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents = loader.load()\n",
    "# Started giving error recently, apparently some breaking change introduced in Langchain latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2743a8ca-dfb5-4115-bda6-00a0281a4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965d904a-d987-4936-a87b-96620fbd7373",
   "metadata": {},
   "source": [
    "#### WebBase Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba9dd5ed-9132-4b69-acfe-e2e7c6f48ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://github.com/sanketana/GenAI-Foudations/blob/main/Week06_RAG_1/notes.md\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7873953e-d1b7-428c-9b59-8ff524e62a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f882de0-5dd4-4355-bb92-f53a77b0f163",
   "metadata": {},
   "source": [
    "## 2) Splitters\n",
    "A document splitter is a utility that takes a large document (or multiple documents) and breaks it into smaller, more manageable chunks of text.\n",
    "\n",
    "#### Types of Splitters in Langchain\n",
    "1. CharacterTextSplitter\n",
    "2. RecursiveCharacterTextSplitter\n",
    "3. TokenTextSplitter\n",
    "4. Markdown / Code Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d57e45-9191-4470-8007-a056dbcc098a",
   "metadata": {},
   "source": [
    "![Example Splitter](Example_Splitter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ecd10-f3fe-43fb-9db2-48f33899c335",
   "metadata": {},
   "source": [
    "| Feature                  | CharacterTextSplitter                        | RecursiveCharacterTextSplitter                          |\n",
    "|---------------------------|-----------------------------------------------|---------------------------------------------------------|\n",
    "| Splitting method          | Fixed-size, raw character cuts               | Tries hierarchical separators (para → sentence → word → char) |\n",
    "| Preserves semantic meaning| ❌ Often cuts in middle of words/sentences    | ✅ Keeps chunks aligned to natural text boundaries       |\n",
    "| Default separators        | [\"\\n\\n\"]                       | `[\"\\n\\n\", \"\\n\", \" \", \"\"]` (paragraph, line, space, char)|\n",
    "| Chunk size handling       | Strict cutoff at `chunk_size`                | Tries largest separator where chunk ≤ `chunk_size`      |\n",
    "| Chunk overlap             | ✅ Supported                                 | ✅ Supported                                            |\n",
    "| Output consistency        | More predictable (always equal-sized chunks) | More variable (chunks may differ in size depending on separators) |\n",
    "| Performance               | Faster, simpler                             | Slightly slower due to recursive splitting logic        |\n",
    "| Readability of chunks     | Poor (fragments of sentences)                 | Better (complete sentences/paragraphs where possible)   |\n",
    "| Best use case             | Very short/simple text; testing              | Long docs, PDFs, transcripts, RAG pipelines             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee149179-a12e-4768-8953-1f3989d4b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d7d19af-5a03-433f-810b-7579f5f6361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "text = \"\"\"Artificial Intelligence is changing the world. It is being used in healthcare, education, and entertainment. \n",
    "\n",
    "However, AI also raises ethical concerns. Bias, privacy, and misuse are important issues.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06ca606a-1a82-42b7-81e8-7ebfda3507a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =50\n",
    "chunk_overlap = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e581f70e-5517-42a6-a9ab-0230c5925856",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8281d76f-1331-4dec-a4ee-00e218e821e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 109, which is longer than the specified 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial Intelligence is changing the world. It is being used in healthcare, education, and entertainment.', 'However, AI also raises ethical concerns. Bias, privacy, and misuse are important issues.']\n"
     ]
    }
   ],
   "source": [
    "char_chunks = c_splitter.split_text(text)\n",
    "print(char_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "370e3821-400e-4c52-8cd8-d8bda1730b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is changing the world. It is being used in healthcare, education, and entertainment.\n",
      "However, AI also raises ethical concerns. Bias, privacy, and misuse are important issues.\n"
     ]
    }
   ],
   "source": [
    "for chunk in char_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3294c600-76c3-45d5-b165-c7be981e7295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artificial Intelligence is changing the world. It', 'world. It is being used in healthcare, education,', 'and entertainment.', 'However, AI also raises ethical concerns. Bias,', 'Bias, privacy, and misuse are important issues.']\n"
     ]
    }
   ],
   "source": [
    "rec_chunks = r_splitter.split_text(text)\n",
    "print(rec_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "295ddab3-dec7-4d6e-91c7-9f2dc49311a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is changing the world. It\n",
      "world. It is being used in healthcare, education,\n",
      "and entertainment.\n",
      "However, AI also raises ethical concerns. Bias,\n",
      "Bias, privacy, and misuse are important issues.\n"
     ]
    }
   ],
   "source": [
    "for chunk in rec_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4b137-4463-4a68-94d7-7eba9ebf3807",
   "metadata": {},
   "source": [
    "## 3) Vectorstores and Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f13bf92-49f1-4a20-afe4-021bbbce17b1",
   "metadata": {},
   "source": [
    "#### Combining loading and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f05fd2-6d82-4706-ab2f-d9106257e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")\n",
    "docs = loader.load()\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e20a8a3b-e667-422e-ae50-b6ef1321de03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
      " 'creator': 'PScript5.dll Version 5.2.2',\n",
      " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
      " 'author': '',\n",
      " 'moddate': '2008-07-11T11:25:23-07:00',\n",
      " 'title': '',\n",
      " 'source': 'MachineLearning-Lecture01.pdf',\n",
      " 'total_pages': 22,\n",
      " 'page': 0,\n",
      " 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pp(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fef243e2-2f05-46a3-bc4f-9a6d3948b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulk Loading PDF\n",
    "loaders = [\n",
    "    PyPDFLoader(\"MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture02.pdf\"),    \n",
    "    PyPDFLoader(\"MachineLearning-Lecture03.pdf\"),    \n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5d1e2f9-cfda-43df-8e59-d03bd928b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d65be5f-ef62-41d9-93e8-6658f4eb66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5bba6c7-2177-4053-97ca-d779acd8c52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "print(len(splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f701e8b5-d20d-48c1-a81c-50258fd81cc1",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f54d89a8-2c51-431f-b481-907a424b6b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-openai\n",
    "!pip install -qU python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da0f59b1-53c2-4a6d-b879-69f6e15b51c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: sk-pr*****\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access your API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"API Key:\", api_key[:5] + \"*****\")  # just to verify it’s loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78a2ab6b-98af-4ce7-a0db-c0458c58f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "# Can also explicitly pass key as openai_api_key=api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8155fb09-4ee0-4476-b894-71709c0a9df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee1 = \"I enjoy drinking coffee in the morning.\"\n",
    "coffee2 = \"I love having a cup of filter coffee when I wake up\"\n",
    "market = \"The stock market had a big crash yesterday.\"\n",
    "mug = \"I crashed the stock of my coffee mug yesterday.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adc1ea09-0d23-415a-b3cb-fd1417195a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee1_embedding = embedding.embed_query(coffee1)\n",
    "coffee2_embedding = embedding.embed_query(coffee2)\n",
    "market_embedding = embedding.embed_query(market)\n",
    "mug_embedding = embedding.embed_query(mug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a5d129d1-19ab-4a41-80d6-6a296314caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f4a0652-c819-4ec8-b94f-7f3e7b35d48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.627351559087536)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array(coffee1_embedding), np.array(coffee2_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f570a395-bb0b-486f-b5b5-806801c21497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.07100796107510074)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array(coffee1_embedding), np.array(market_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad38d47-cd9e-4c9c-bbe0-8603c6c5225a",
   "metadata": {},
   "source": [
    "### Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3050ae3d-f672-479c-9dbe-1df1d0ed7fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "32ad48c7-8d76-4db1-99cb-7a4973b184e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "891c5846-9d52-4911-afed-ff4002b23605",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma'\n",
    "!rm -rf ./docs/chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c2d3ae0-8632-4215-909c-853e94690432",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c503c5fd-03b0-4687-99de-21721204cec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b148ccc6-04a2-4969-86c1-53e7841f7a26",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48124048-b48d-4299-aa94-64269aadad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email i can ask for help\"\n",
    "docs = vectordb.similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66ce59a2-1924-45cd-b72b-058f9c79ea00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a67a165e-a146-4cb9-9cf1-4b3a5d4c8e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cs229-qa@cs.stanford.edu. This goes to an account that's read by all the TAs and me. So \\nrather than sending us email individually, if you send email to this account, it will \\nactually let us get back to you maximally quickly with answers to your questions.  \\nIf you're asking questions about homework problems, please say in the subject line which \\nassignment and which question the email refers to, since that will also help us to route \\nyour question to the appropriate TA or to me appropriately and get the response back to \\nyou quickly.  \\nLet's see. Skipping ahead — let's see — for homework, one midterm, one open and term \\nproject. Notice on the honor code. So one thing that I think will help you to succeed and \\ndo well in this class and even help you to enjoy this class more is if you form a study \\ngroup.  \\nSo start looking around where you're sitting now or at the end of class today, mingle a \\nlittle bit and get to know your classmates. I strongly encourage you to form study groups \\nand sort of have a group of people to study with and have a group of your fellow students \\nto talk over these concepts with. You can also post on the class newsgroup if you want to \\nuse that to try to form a study group.  \\nBut some of the problems sets in this class are reasonably difficult. People that have \\ntaken the class before may tell you they were very difficult. And just I bet it would be \\nmore fun for you, and you'd probably have a better learning experience if you form a\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bf20f-2f0e-418d-8158-ee6aadf12251",
   "metadata": {},
   "source": [
    "### Failure Cases - Duplicate Chunks in Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1a8210f9-bba3-4f6e-bc3c-1adf5d68f850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page_label': '9', 'page': 8, 'creator': 'PScript5.dll Version 5.2.2', 'source': 'MachineLearning-Lecture01.pdf', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'total_pages': 22, 'creationdate': '2008-07-11T11:25:23-07:00', 'title': ''}, page_content='those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it\\'s free, and for the purposes of this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine learning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, like, ten years ago came \\ninto his office and he said, \"Oh, professor, professor, thank you so much for your')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about the matlab\"\n",
    "docs = vectordb.similarity_search(question, k=5)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6473a39-dae9-4331-b811-9fd3f1c520f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'author': '', 'total_pages': 22, 'source': 'MachineLearning-Lecture01.pdf', 'page_label': '9', 'moddate': '2008-07-11T11:25:23-07:00', 'page': 8, 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creationdate': '2008-07-11T11:25:23-07:00', 'title': '', 'creator': 'PScript5.dll Version 5.2.2'}, page_content='those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it\\'s free, and for the purposes of this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine learning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, like, ten years ago came \\ninto his office and he said, \"Oh, professor, professor, thank you so much for your')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a2234-e443-4caf-a875-95ea9df176ed",
   "metadata": {},
   "source": [
    "### Failure Cases - Semantic Lookup ignoring Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "12f6cce0-96f9-41b3-af79-4fd8dee6ad7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2008-07-11T11:25:03-07:00', 'page_label': '1', 'page': 0, 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creationdate': '2008-07-11T11:25:03-07:00', 'total_pages': 16, 'title': '', 'author': '', 'source': 'MachineLearning-Lecture03.pdf'}\n",
      "{'moddate': '2008-07-11T11:25:03-07:00', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'total_pages': 16, 'creationdate': '2008-07-11T11:25:03-07:00', 'author': '', 'page_label': '15', 'source': 'MachineLearning-Lecture03.pdf', 'title': '', 'page': 14, 'creator': 'PScript5.dll Version 5.2.2'}\n",
      "{'author': '', 'page': 6, 'creationdate': '2008-07-11T11:25:03-07:00', 'page_label': '7', 'creator': 'PScript5.dll Version 5.2.2', 'title': '', 'source': 'MachineLearning-Lecture03.pdf', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'moddate': '2008-07-11T11:25:03-07:00', 'total_pages': 16}\n",
      "{'source': 'MachineLearning-Lecture03.pdf', 'creationdate': '2008-07-11T11:25:03-07:00', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'page': 2, 'author': '', 'title': '', 'moddate': '2008-07-11T11:25:03-07:00', 'page_label': '3', 'total_pages': 16, 'creator': 'PScript5.dll Version 5.2.2'}\n",
      "{'source': 'MachineLearning-Lecture02.pdf', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'page': 0, 'total_pages': 18, 'author': '', 'title': '', 'page_label': '1', 'moddate': '2008-07-11T11:25:05-07:00', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:05-07:00'}\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about regression in the third lecture\"\n",
    "docs = vectordb.similarity_search(question, k=5)\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5622377-0e35-4542-a87f-c6cbd85a2b77",
   "metadata": {},
   "source": [
    "## 4) Retrieval\n",
    "Fetching the most relevant pieces of external information (chunks of documents, knowledge base, etc.) to provide extra context to the LLM before it generates an answer.\n",
    "\n",
    "#### Types of Retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c17bf5c-736b-497b-9060-c596b3c0d7d4",
   "metadata": {},
   "source": [
    "| Attribute            | Vector Similarity                          | BM25 / Keyword                  | Hybrid Search                     | Re-ranking                          | Structured Retrieval                  |\n",
    "|----------------------|-------------------------------------------|---------------------------------|----------------------------------|------------------------------------|--------------------------------------|\n",
    "| How It Works          | Embed query & docs, find nearest vectors | TF-IDF based keyword match       | Combines vector + keyword search  | Retrieve many, rerank with model   | Query structured DB or API            |\n",
    "| Strengths             | Captures semantic meaning                 | Exact keyword matching           | Balances semantic & lexical      | High precision ranking             | Accurate for structured facts         |\n",
    "| Weaknesses            | Misses exact keywords                     | Fails on semantic similarity     | More complex infra               | Expensive at scale                  | Needs schema alignment                |\n",
    "| When to Use           | General semantic search                   | Legal, technical, IDs           | Production-grade RAG             | Customer-facing apps, high accuracy | Enterprise + DB + knowledge graph    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d89345-3124-4281-bb9d-9d0186ca440d",
   "metadata": {},
   "source": [
    "#### Maximum Marginal Relevance (MMR)\n",
    "- You may not always want to choose the most similar responses\n",
    "- Could give a very narrow view of the topic\n",
    "- Eg:\n",
    "1. **Wikipedia / Photosynthesis**  \n",
    "   - **Without MMR**: Top-k retrieves 3 paragraphs all about the light reaction.  \n",
    "   - **With MMR**: You get **light reaction + Calvin cycle + chloroplast structure** — comprehensive and non-repetitive.  \n",
    "\n",
    "2. **News Articles / Election Results**  \n",
    "   - **Without MMR**: Top-k might select 3 snippets all repeating **who won**.  \n",
    "   - **With MMR**: You get **winner + voter turnout + reactions from parties and citizens** — broader context.  \n",
    "\n",
    "3. **Product Reviews / Smartphone Pros**  \n",
    "   - **Without MMR**: Top-k selects 3 reviews all saying **camera is good**.  \n",
    "   - **With MMR**: You get **camera + battery + display quality** — highlights diverse advantages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8c3cae18-1649-4d5d-8af4-ade6f0ec7947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people c'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)\n",
    "docs_ss[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "12f91037-e0d3-492e-9b26-a6619357a8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people c'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "793285aa-36d7-45e8-8e03-5358a21268e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people c'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)\n",
    "docs_mmr[0].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ed38734-88ee-4bc7-b47c-2368d543e801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'least squares regression being a bad idea for classification problems and then I did a \\nbunch of mat'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9594d80d-fb48-4e4c-a9d5-31d9a1b7bb2b",
   "metadata": {},
   "source": [
    "#### Metadata Based Search\n",
    "Augumenting similarity search with exact metadata wherever possible\n",
    "Eg: Search for regression in 3rd lecture transcript which is MachineLearning-Lecture03.pdf (metadata filer Source: MachineLearning-Lecture03.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "587cf2c3-e882-4f62-bdcb-80cc6a4fba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\"\n",
    "\n",
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"MachineLearning-Lecture03.pdf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca8384e8-1b6e-4ae2-8eab-ddf8cd9b7d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'creationdate': '2008-07-11T11:25:03-07:00', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'author': '', 'total_pages': 16, 'moddate': '2008-07-11T11:25:03-07:00', 'page_label': '1', 'page': 0, 'title': '', 'source': 'MachineLearning-Lecture03.pdf', 'creator': 'PScript5.dll Version 5.2.2'}\n",
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'author': '', 'creationdate': '2008-07-11T11:25:03-07:00', 'title': '', 'page': 14, 'total_pages': 16, 'creator': 'PScript5.dll Version 5.2.2', 'source': 'MachineLearning-Lecture03.pdf', 'page_label': '15', 'moddate': '2008-07-11T11:25:03-07:00'}\n",
      "{'page': 6, 'moddate': '2008-07-11T11:25:03-07:00', 'source': 'MachineLearning-Lecture03.pdf', 'total_pages': 16, 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'author': '', 'creationdate': '2008-07-11T11:25:03-07:00', 'title': '', 'page_label': '7'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a35ce-3a5f-429e-be9c-dd2ed5941faa",
   "metadata": {},
   "source": [
    "#### Metadata Self Query Retriever\n",
    "\n",
    "SelfQueryRetriever uses an LLM to dynamically translate your natural language question into both semantic + metadata queries so that your vector DB returns the most relevant and context-aware chunks.\n",
    "\n",
    "##### What it does internally:\n",
    "- Determines semantic intent\n",
    "- Determines metadata filters if applicable\n",
    "- Sends the query to vector DB with filters\n",
    "\n",
    "##### Why this is powerful\n",
    "- You don’t need to manually write filters or craft queries.\n",
    "- The LLM automatically “understands” the schema and selects relevant docs.\n",
    "- Works well for RAG pipelines, especially with metadata-rich corpora (like CS229 transcripts with topics, lecture numbers, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b73cf61-5ec0-42dc-9341-2b1be4e3c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "727fffd2-ed57-4047-b887-cdd07eafbb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of `MachineLearning-Lecture01.pdf`, `MachineLearning-Lecture02.pdf`, or `MachineLearning-Lecture03.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78ae6d0a-7365-4f90-ba7d-3718da5e107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a0eb394-14be-4d3a-be8c-ea985b869b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e2874953-6298-4ef7-905c-b50df73d44a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da4414ed-5b84-421d-ba8e-b6bb83fe2136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '', 'page_label': '3', 'author': '', 'source': 'MachineLearning-Lecture03.pdf', 'page': 2, 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'moddate': '2008-07-11T11:25:03-07:00', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:03-07:00', 'total_pages': 16}\n",
      "{'title': '', 'total_pages': 16, 'page': 10, 'moddate': '2008-07-11T11:25:03-07:00', 'creator': 'PScript5.dll Version 5.2.2', 'page_label': '11', 'source': 'MachineLearning-Lecture03.pdf', 'author': '', 'creationdate': '2008-07-11T11:25:03-07:00', 'producer': 'Acrobat Distiller 8.1.0 (Windows)'}\n",
      "{'title': '', 'source': 'MachineLearning-Lecture03.pdf', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'page': 11, 'moddate': '2008-07-11T11:25:03-07:00', 'creationdate': '2008-07-11T11:25:03-07:00', 'total_pages': 16, 'page_label': '12', 'creator': 'PScript5.dll Version 5.2.2', 'author': ''}\n",
      "{'source': 'MachineLearning-Lecture03.pdf', 'creationdate': '2008-07-11T11:25:03-07:00', 'page': 6, 'author': '', 'title': '', 'total_pages': 16, 'creator': 'PScript5.dll Version 5.2.2', 'moddate': '2008-07-11T11:25:03-07:00', 'page_label': '7', 'producer': 'Acrobat Distiller 8.1.0 (Windows)'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0fdca4-3a9c-4ab2-92fa-658d82f4e2f6",
   "metadata": {},
   "source": [
    "## 5) Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55960e70-dd4a-454e-921c-db222b1fce53",
   "metadata": {},
   "source": [
    "![RAG Question Answering](RAG_Question_Answering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daea52bb-aa13-486c-8fe7-bbe50e0d7373",
   "metadata": {},
   "source": [
    "![RAG_RetrievalQA_chain](RAG_RetrievalQA_chain.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b624f818-aa8b-475a-a024-d59746893168",
   "metadata": {},
   "source": [
    "#### RetrievalQA Methods\n",
    "1. Stuff\n",
    "2. Map Reduce\n",
    "3. Refine\n",
    "4. Map Rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7bb6a1-3b8a-48f7-a538-cadeacae88a6",
   "metadata": {},
   "source": [
    "![RAG_RetrievalQA_methods](RAG_RetrievalQA_methods.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59adc446-ad4e-4db7-8fa5-62d6ea0d0205",
   "metadata": {},
   "source": [
    "#### Retrieval Strategies Cheatsheet\n",
    "\n",
    "| Strategy      | How it Works | Pros | Cons | Best When | Example |\n",
    "|---------------|--------------|------|------|-----------|---------|\n",
    "| **Stuff**     | Put all retrieved docs directly into the prompt | Simple, fast, keeps full context | Limited by LLM context window, irrelevant info may confuse | Few and short docs | FAQ bot: “What’s your refund policy?” |\n",
    "| **Map Reduce**| LLM processes each doc separately (map), then combines summaries (reduce) | Handles many docs, avoids overflow | Slower (many LLM calls), may lose detail | Summarizing large sets of long docs | Research assistant summarizing 100 news articles |\n",
    "| **Refine**    | Start with one doc → draft answer, then iteratively refine with others | Produces coherent, detailed answers; balances context | Sequential (slower), depends heavily on first doc | Each doc adds incremental clarification | Contract review: “What are the late payment penalties?” |\n",
    "| **Map Rerank**| LLM processes each doc separately, scores relevance, selects best one(s) | Precision-focused, filters noise | May miss synthesis across docs | Many docs but only one/few truly relevant | Fact Q&A: “Who won the Nobel Prize in Physics in 2024?” |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8d9fc28-27b3-4ba9-a0e6-d939b871aa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAI\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c263e9aa-4edf-4b18-9f93-6fba10061b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h_/_l7_dhxd33z3dgrhs7gh3z480000gn/T/ipykernel_26972/3017790310.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma'\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "33a93f10-0a78-483f-a754-30dcdc016e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "13e70c76-a348-4990-9cf4-62ecf217375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "153a4c96-674e-48b8-8976-831862a5baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5f06c11d-bf10-4bae-b901-397f57f2b3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h_/_l7_dhxd33z3dgrhs7gh3z480000gn/T/ipykernel_26972/3292084118.py:8: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the content about', 'result': 'The content provides information about the online resources and communication methods for a class, likely a computer science course (CS229) at Stanford University. It mentions the course homepage (http://cs229.stanford.edu) where homework assignments, solutions, and detailed lecture notes are posted. It also discusses a class newsgroup (su.class.cs229) for student discussions and forming study groups, which is not monitored by the teaching staff. For contacting the teaching staff, students are advised to use the email address cs229-qa@cs.stanford.edu. The content also encourages forming study groups to tackle difficult problem sets and enhance the learning experience.'}\n"
     ]
    }
   ],
   "source": [
    "# Chain Type = Stuff (default)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "question = \"What is the content about\"\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "20ea6ae5-ecf4-49e8-be5e-b772b265836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the content about', 'result': 'The content is about the online resources available for a class. It includes information on the class homepage where homework assignments and solutions are posted, detailed lecture notes, a newsgroup for class discussions, and a shared email account for contacting the teaching staff. It also advises students on how to contact the teaching staff effectively and encourages the formation of study groups to tackle difficult problem sets.'}\n"
     ]
    }
   ],
   "source": [
    "# Chain Type = Map Reduce --> Suitable for large corpus where retriever return document bigger than context window\n",
    "mr_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type = \"map_reduce\"\n",
    ")\n",
    "\n",
    "question = \"What is the content about\"\n",
    "result = mr_chain({\"query\": question})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34923918-af11-4269-9526-e38140d176cd",
   "metadata": {},
   "source": [
    "### Prompt Templates\n",
    "\n",
    "A prompt template is a reusable, structured instruction with placeholders that guides an LLM on how to format and answer a question using provided inputs.\n",
    "\n",
    "#### Benefits\n",
    "- **Control the Answer Style**  \n",
    "  Ensure answers have a consistent tone, length, or format.\n",
    "\n",
    "- **Guide the LLM to Use Only Retrieved Context**  \n",
    "  Prevents hallucination by instructing the model to rely solely on the retrieved documents.\n",
    "\n",
    "- **Support Special Tasks**  \n",
    "  Enables tasks like summarization, comparison, or structured output.\n",
    "\n",
    "- **Make It Domain-Specific**  \n",
    "  Tailor instructions for specific industries (legal, medical, educational) for more accurate responses.\n",
    "\n",
    "- **Improve Consistency for Evaluation**  \n",
    "  Forces outputs into predictable formats (JSON, markdown, bullet points), making grading or analysis easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d97efc56-0e2d-403c-b18a-c39ee7763f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0bac8686-06ab-4e81-876d-7b994ab7b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\":QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ddd97cc1-fc14-4ad4-8f2a-58db4369a26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, probability is a class topic, as it is mentioned that discussion sections will cover prerequisites like probability and statistics. Thanks for asking!'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a0033-064b-4a2e-97e1-991d7b7f7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2c044b6f-a640-4c83-942f-846539d5f2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The prerequisites are needed to ensure that students have the foundational knowledge required to tackle the challenging problem sets and concepts in the course. This background helps students engage more effectively with the material, participate in study groups, and apply advanced algorithms efficiently. Thanks for asking!'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Why are those prerequisites needed?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c58fa2-3173-48fa-8324-260836c369d3",
   "metadata": {},
   "source": [
    "#### RetrievalQA to LCEL Upgrade in Langchain\n",
    "LCEL = Langchain Expression Language\n",
    "- LCEL stands for LangChain Expression Language.\n",
    "- It is a declarative layer (or DSL-style syntax) for orchestrating LangChain “chains” (i.e. compositions of prompts, models, transformations, etc.)\n",
    "- The idea is: instead of manually wiring chain steps with imperative code, you declare what you want with composable “runnables” and use operators (like the pipe |) to define the flow.\n",
    "- Under the hood, components in LCEL are built upon a Runnable interface — every step is a Runnable (or composed of Runnables) that supports invoke, batch, stream, etc.\n",
    "\n",
    "https://python.langchain.com/docs/versions/migrating_chains/retrieval_qa/\n",
    "\n",
    "https://lilianweng.github.io/posts/2023-06-23-agent/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4de367-7d13-42e2-bc2e-4a1561c07768",
   "metadata": {},
   "source": [
    "## 5) Conversational Retrieval\n",
    "\n",
    "It is a special LangChain chain designed for conversational RAG use cases.\n",
    "\n",
    "Unlike RetrievalQA, which just answers standalone queries, ConversatinalRetrievalChain is chat aware - it takes into account the conversation history along with the retrieved documents when answering. It maintains a conversation memory.\n",
    "\n",
    "For eg: If a user asks \"Who founded it?\", it knows \"it\" refers to the company mentioned in the last turn. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f18bc5-57b8-4bb9-8c28-dadb67189e4e",
   "metadata": {},
   "source": [
    "#### Setup Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d25146-7e27-4c1b-8b9d-60931bb1189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-openai\n",
    "!pip install -qU python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "868c574a-d06f-4695-9f06-484c5dc88994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6ba1e090-dcaf-449c-b1ea-0c58d97d701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fe7a00-f3fc-4dfb-b47e-b40d01e0545f",
   "metadata": {},
   "source": [
    "#### Load Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3964a-0ac4-44ed-bf67-af005abf062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6ba9250c-7507-48c4-bdfa-e3fa7da6c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3043fa3b-b7c2-42f0-8929-576809174e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "344fa37f-64ec-4e7c-a7e4-3ee0f2d3ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68790484-753d-452f-b2d3-57487694a89d",
   "metadata": {},
   "source": [
    "#### Run basic similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9cc50dcb-81ed-4e50-a0bf-9dc67b9b5a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who is the main instructor for the course?\"\n",
    "docs = vectordb.similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2dd871f7-e047-492c-9e9a-e799c5f2b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of the class, and then we'll start to talk a bit about machine learning.  \n",
      "By way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \n",
      "I personally work in machine learning, and I've worked on it for about 15 years now, and \n",
      "I actually think that machine learning is the most exciting field of all the computer \n",
      "sciences. So I'm actually always excited about teaching this class. Sometimes I actually \n",
      "think that machine learning is not only the most exciting thing in computer science, but \n",
      "the most exciting thing in all of human endeavor, so maybe a little bias there.  \n",
      "I also want to introduce the TAs, who are all graduate students doing research in or \n",
      "related to the machine learning and all aspects of machine learning. Paul Baumstarck \n",
      "works in machine learning and computer vision. Catie Chang is actually a neuroscientist \n",
      "who applies machine learning algorithms to try to understand the human brain. Tom Do \n",
      "is another PhD student, works in computational biology and in sort of the basic \n",
      "fundamentals of human learning. Zico Kolter is the head TA — he's head TA two years \n",
      "in a row now — works in machine learning a nd applies them to a bunch of robots. And \n",
      "Daniel Ramage is — I guess he's not here  — Daniel applies l earning algorithms to' metadata={'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'total_pages': 22, 'creationdate': '2008-07-11T11:25:23-07:00', 'page_label': '1', 'page': 0, 'source': 'MachineLearning-Lecture01.pdf', 'creator': 'PScript5.dll Version 5.2.2', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'title': ''}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e9499-19ef-48fd-93d2-11c5c2f539d3",
   "metadata": {},
   "source": [
    "#### Setup Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7df7ce31-65c5-42c6-b85f-c0203154a5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd100ca-c9a3-4c1d-ad5b-afafeed7a424",
   "metadata": {},
   "source": [
    "#### Adding Memory\n",
    "\n",
    "Stores the entire conversation history in memory, and gives the chatbot a \"short-term memory\" of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f8d6994f-4dc2-44e4-8b6a-38561a5b0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fea6e1-e29f-4036-bfca-1d05fab62ea0",
   "metadata": {},
   "source": [
    "#### Create a Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "14968f4b-1ea0-4a16-8c8e-cefc1ec391ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8cf5bc00-3021-434b-99c3-b88b9636d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a class topic?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9d483352-48e4-4279-aedd-e358254d7868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, familiarity with basic probability and statistics is assumed as a prerequisite for the class. The class expects students to know concepts such as random variables, expectation, and variance. However, some discussion sections will serve as a refresher for these topics if needed.'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dc67c784-dc88-441a-9cd6-b0f050dc2a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Familiarity with basic probability and statistics is required as a prerequisite for the class because the course likely involves concepts and techniques that rely on understanding random variables, expectation, variance, and other statistical principles. These are foundational elements in many areas of study, including machine learning, where statistical methods are used to analyze data and make predictions. The course assumes that students have this background knowledge to effectively engage with the material and apply it in programming tasks, primarily in MATLAB or Octave.'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Why are those prerequisites needed?\"\n",
    "result = qa({\"question\": question})\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588ff20-40d6-4878-9f57-2b13bc67b132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot ready! Type 'exit' to stop.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  who is the instructor of this course\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: The instructor of the course is Andrew Ng.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  tell me something about him\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Andrew Ng is an instructor for the CS229 machine learning class. He has worked in the field of machine learning for about 15 years and is very passionate about it, considering it the most exciting field in computer science and possibly in all of human endeavor.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  tell me about some of the companies he founded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: I don't know.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what topics in machine learning has he covered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: The context provided does not specify the exact topics in machine learning that Andrew Ng has covered in his lecture. It mainly discusses the logistics of the class, introduces the teaching assistants, and mentions some student projects related to machine learning. If you are looking for specific topics, you might want to refer to the course syllabus or lecture notes from CS229.\n"
     ]
    }
   ],
   "source": [
    "# Chat loop\n",
    "print(\"Chatbot ready! Type 'exit' to stop.\\n\")\n",
    "while True:\n",
    "    question = input(\"You: \")\n",
    "    if question.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        print(\"Chatbot: Goodbye 👋\")\n",
    "        break\n",
    "    result = qa({\"question\": question})\n",
    "    print(\"Chatbot:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e75dd-04d4-47c4-b460-c49fbda87345",
   "metadata": {},
   "source": [
    "# 🔹 LangChain Memory Types Comparison\n",
    "\n",
    "| Memory Type | How It Works | ✅ Pros | ❌ Cons | 🔥 Best Use Case |\n",
    "|-------------|--------------|---------|---------|------------------|\n",
    "| **ConversationBufferMemory** | Stores the full conversation transcript (all turns). | Simple, easy to use, preserves entire chat history. | Grows too large → may hit token limits on long chats. | Small chatbots, short Q&A sessions. |\n",
    "| **ConversationBufferWindowMemory** | Stores only the **last N turns**. | Controls token usage, fast. | Loses older context (may forget important details). | Customer support chat, where only recent turns matter. |\n",
    "| **ConversationSummaryMemory** | Summarizes conversation into shorter text. | Efficient, compresses history, avoids token overflow. | Summaries may lose details / nuance. | Long conversations (e.g., tutoring, therapy bots). |\n",
    "| **ConversationSummaryBufferMemory** | Keeps last N turns + summary of older turns. | Balance between detail + efficiency. | Slightly more complex to configure. | Multi-session chat assistants. |\n",
    "| **VectorStoreRetrieverMemory** | Embeds past interactions in a vector DB and retrieves relevant history by similarity. | Semantic recall (remembers even if phrasing differs). | Needs a vector DB + embeddings, retrieval can be slower. | Knowledge-grounded agents, FAQ bots, personal assistants. |\n",
    "| **ConversationKGMemory** | Extracts entities + relations into a knowledge graph. | Structured recall of facts, good for reasoning. | More complex setup, can miss nuance. | Assistants that need to track facts (e.g., “Alice works at Microsoft”). |\n",
    "| **EntityMemory** | Tracks facts about specific entities (people, orgs, places). | Great for personalization, fact persistence. | Limited to entity-centric information. | Personalized assistants, role-playing bots. |\n",
    "| **CombinedMemory** | Mixes multiple memory strategies. | Very flexible, covers multiple needs. | More setup, risk of redundancy. | Advanced agents needing hybrid strategies. |\n",
    "| **Custom Memory** | User-defined state storage (dicts, databases, workflows). | Fully flexible, app-specific. | You have to build & maintain it. | Non-conversational agents, task workflows, profile management. |\n",
    "\n",
    "---\n",
    "\n",
    "# 🔹 Quick Rule of Thumb\n",
    "\n",
    "- ✅ **Short conversations** → `ConversationBufferMemory`  \n",
    "- ✅ **Medium conversations** → `ConversationBufferWindowMemory`  \n",
    "- ✅ **Long conversations** → `ConversationSummaryMemory` or `ConversationSummaryBufferMemory`  \n",
    "- ✅ **Semantic recall** → `VectorStoreRetrieverMemory`  \n",
    "- ✅ **Fact-tracking** → `EntityMemory` or `ConversationKGMemory`  \n",
    "- ✅ **Advanced assistants** → `CombinedMemory`  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fa8994-2ecd-44bc-8fb3-fe6208e46597",
   "metadata": {},
   "source": [
    "# 🔹 LangChain Chain Types Comparison\n",
    "\n",
    "| Chain Type | How It Works | ✅ Pros | ❌ Cons | 🔥 Best Use Case |\n",
    "|------------|--------------|---------|---------|------------------|\n",
    "| **LLMChain** | Prompt template → LLM → Output | Simple, flexible, building block for everything else | Limited (single-step only) | Text generation, summarization, classification, extraction |\n",
    "| **SimpleSequentialChain** | Passes output of one chain as input to the next | Easy to set up multi-step flow | Only single input/output per step | Step-by-step pipelines (e.g., extract → summarize) |\n",
    "| **SequentialChain** | More flexible sequential flow with multiple inputs/outputs | Can handle complex workflows | Setup more verbose than SimpleSequentialChain | Multi-step tasks with branching or multiple variables |\n",
    "| **RouterChain** | Routes inputs to different chains based on conditions | Dynamic, modular | Requires good routing logic (classifier/prompt) | Multi-domain assistants (e.g., coding vs FAQ vs math) |\n",
    "| **RetrievalQA** | Retrieves docs → stuffs into prompt → LLM answers | Straightforward, works well for Q&A | No chat history, single query only | One-off document Q&A, FAQ bots |\n",
    "| **ConversationalRetrievalChain** | Retrieves docs + adds chat history via memory → LLM answers | Maintains context, supports multi-turn chat | More complex, higher token usage | Chatbot-style assistants over custom knowledge |\n",
    "| **Summarization Chains** (`stuff`, `map_reduce`, `refine`) | Summarize across multiple docs/chunks | Handles long documents, different strategies available | May be slower/expensive (map_reduce/refine) | Summarizing books, PDFs, transcripts |\n",
    "| **HyDE (Hypothetical Document Embedding) Chain** | Generates hypothetical answer → embeds → retrieves relevant docs | Improves retrieval quality in some cases | Extra LLM call (slower, costlier) | When retriever struggles with recall |\n",
    "| **Transform Chains** | Pre-process or transform input before passing to LLM | Useful for data cleaning or translations | Usually part of larger pipeline, not standalone | Language translation, text cleaning, entity extraction |\n",
    "| **Custom Chains** | Build your own chain by subclassing `Chain` | Fully flexible, app-specific | You need to code it yourself | Special workflows not covered by built-ins |\n",
    "\n",
    "---\n",
    "\n",
    "# 🔹 Quick Rule of Thumb\n",
    "\n",
    "- ✅ **Basic prompt → output** → `LLMChain`  \n",
    "- ✅ **Multi-step pipelines** → `SequentialChain` or `SimpleSequentialChain`  \n",
    "- ✅ **Document Q&A (single query)** → `RetrievalQA`  \n",
    "- ✅ **Chatbot over docs** → `ConversationalRetrievalChain`  \n",
    "- ✅ **Summarizing large docs** → Summarization Chains (`map_reduce`, `refine`)  \n",
    "- ✅ **Specialized routing** → `RouterChain`  \n",
    "- ✅ **When recall is poor** → `HyDE`  \n",
    "- ✅ **Custom workflows** → `Custom Chain`  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4454556-7f31-4de6-86e4-5b29e6c54bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
