# Week 06: Pre-Reading Materials

## Required Reading
1. **"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"** - Lewis et al. (2020)
   - Original RAG paper and methodology

2. **"RAG vs Fine-tuning: Which is Better?"** - Comparison analysis
   - When to use RAG vs model fine-tuning

## Recommended Reading
1. **LangChain RAG Documentation**
   - Practical RAG implementation guide
   - URL: https://python.langchain.com/docs/use_cases/question_answering

2. **"Advanced RAG Techniques"** - Best practices and optimizations

3. **"Evaluating RAG Systems"** - Metrics and benchmarking approaches

## Technical Prerequisites
- Vector databases (Week 05)
- Embeddings and similarity search (Week 04)
- Language model APIs and prompt engineering
- Document processing and chunking strategies

## Code Preparation
```bash
pip install langchain
pip install openai
pip install chromadb
pip install tiktoken
pip install pypdf
pip install python-docx
```

## Videos to Watch
1. **"RAG Explained: From Theory to Practice"** - (50 minutes)
2. **"Building Production RAG Systems"** - (40 minutes)
3. **"Common RAG Pitfalls and Solutions"** - (30 minutes)

## Preparation Exercises
1. Review vector database implementations
2. Practice document chunking strategies
3. Experiment with different embedding models
4. Test prompt variations for QA tasks

## Key Concepts to Master
- Document preprocessing and chunking
- Retrieval ranking and filtering
- Context construction and management
- Prompt engineering for RAG
- Evaluation methodologies

## Research Questions
1. How does chunk size affect RAG performance?
2. What are the trade-offs between accuracy and speed?
3. How do you handle domain-specific knowledge?
4. What are effective evaluation strategies?

## Estimated Reading Time: 4-5 hours 