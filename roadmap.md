# üìç GenAI Curriculum Roadmap

This document outlines the phased learning journey for our Generative AI program. Each phase builds upon the previous one to progressively deepen understanding and expand practical skills.

---

## üìò Phase 1: Foundations (12 Weeks)
**Focus:** GenAI ecosystem, API usage, prompt engineering & Retrieval-Augmented Generation (RAG)  

**Goal:** Build a working GenAI application using LLM APIs + RAG by Week 12

- ‚Å†Intro to LLMs, GenAI use cases
- ‚Å†Prompt Engineering (zero-shot, few-shot, role-based)
- ‚Å†Using OpenAI APIs (chat & completion)
- ‚Å†Embeddings & Semantic Search
- ‚Å†Vector DBs like ChromaDB
- ‚Å†Retrieval-Augmented Generation (RAG)
- ‚Å†Streamlit for front-end
- ‚Å†Calling external APIs from your LLM app
- ‚Å†Structuring prompts, using function calling
- ‚Å†Deploying your GenAI app on HuggingFace/Vercel

---

## ‚öôÔ∏è Phase 2: Building with GenAI (12 Weeks)
**Focus:** Agents, chains, tool integration, AI Ops

**Goal:** Go beyond basics ‚Äî build apps with agents, integrate tools, understand infra-level impact
- Agent frameworks and tools (LangGraph, CrewAI, Autogen)  
- Multi-agent orchestration and use cases  
- Designing LLM workflows with chains and memory  
- Tool integration: search, code, APIs, file parsing  
- Structured output and planning  
- Observability and debugging  
- RAG deep-dive: chunking strategies, advanced retrieval  
- Production concerns: rate limits, cost, latency, reliability

---

## üî¨ Phase 3: Advanced (Optional / TBD)
**Focus:** MCP Servers and deeper system-level integration. To be finalised based on the feedback from the previous phases

**Goal:** Build and deploy self-hosted, modular, and autonomous GenAI applications using MCP servers, LLM orchestration frameworks, and custom tooling pipelines for end-to-end GenAI workflows.

- Building local and cloud-hosted MCP servers  
- Advanced tool calling and function execution  
- Serving custom agents and workflows at scale  
- Hybrid architectures and custom backends  