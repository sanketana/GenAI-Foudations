{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158910a7-e43c-48f3-824a-0d16de6d165f",
   "metadata": {},
   "source": [
    "Basic RAG Components\n",
    "1. Loading\n",
    "2. Splitting\n",
    "3. Vectorstore and Embedding\n",
    "4. Retrieval\n",
    "5. Q/A generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59391e0-68fc-4647-a8e0-46a97408360a",
   "metadata": {},
   "source": [
    "1. Text Loader\n",
    "2. CSV Loader\n",
    "3. PDF Loader\n",
    "4. Youtube Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a207eadd-f13d-44d9-b31d-6954c222e464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01.pdf \u001b[34mvenv\u001b[m\u001b[m\n",
      "RAG.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7216c4f-2072-43ba-aa1c-84795aa43104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Using cached langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.30-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached sqlalchemy-2.0.43-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached orjson-3.11.3-cp313-cp313-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached zstandard-0.25.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Using cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached sqlalchemy-2.0.43-cp313-cp313-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading langsmith-0.4.30-py3-none-any.whl (386 kB)\n",
      "Using cached orjson-3.11.3-cp313-cp313-macosx_15_0_arm64.whl (127 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached zstandard-0.25.0-cp313-cp313-macosx_11_0_arm64.whl (640 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, SQLAlchemy, pydantic-core, orjson, jsonpatch, annotated-types, requests-toolbelt, pydantic, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/14\u001b[0m [langchain][0m \u001b[32m13/14\u001b[0m [langchain]core]h]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.43 annotated-types-0.7.0 jsonpatch-1.33 langchain-0.3.27 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langsmith-0.4.30 orjson-3.11.3 pydantic-2.11.9 pydantic-core-2.33.2 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspection-0.4.1 zstandard-0.25.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.3.76)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2.32.5 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Using cached aiohttp-3.12.15-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.4.30)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=2.1.0 (from langchain-community)\n",
      "  Using cached numpy-2.3.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.7.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.6.4-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.3.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.20.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./venv/lib/python3.13/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.4.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Using cached langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "Using cached aiohttp-3.12.15-cp313-cp313-macosx_11_0_arm64.whl (466 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.6.4-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.1-cp313-cp313-macosx_11_0_arm64.whl (88 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached frozenlist-1.7.0-cp313-cp313-macosx_11_0_arm64.whl (45 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached numpy-2.3.3-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Using cached propcache-0.3.2-cp313-cp313-macosx_11_0_arm64.whl (41 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [langchain-community] \u001b[32m15/16\u001b[0m [langchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 dataclasses-json-0.6.7 frozenlist-1.7.0 httpx-sse-0.4.1 langchain-community-0.3.29 marshmallow-3.26.1 multidict-6.6.4 mypy-extensions-1.1.0 numpy-2.3.3 propcache-0.3.2 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0 yarl-1.20.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.1.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Downloading pypdf-6.1.0-py3-none-any.whl (322 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-6.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-community\n",
    "!pip install pypdf\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b4fdd46-5f09-41ef-a5c6-cd134be39c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54325548-dca5-4c26-83eb-b313438c8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6775fbcd-2962-43a7-81f0-7af9981e7862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "466d3096-beff-4563-87af-11c14ebd7deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbd572cf-8f18-4db6-8a5d-c2cc391e2072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67322faf-2074-461a-b15c-d502fd3e7486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of the class, and then we'll start to talk a bit about machine learning.  \n",
      "By way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \n",
      "I personally work in machine learning, and I've worked on it for about 15 years now, and \n",
      "I actually think that machine learning is the most exciting field of all the computer \n",
      "sciences. So I'm actually always excited about teaching this class. Sometimes I actually \n",
      "think that machine learning is not only the most exciting thing in computer science, but \n",
      "the most exciting thing in all of human endeavor, so maybe a little bias there.  \n",
      "I also want to introduce the TAs, who are all graduate students doing research in or \n",
      "related to the machine learning and all aspects of machine learning. Paul Baumstarck \n",
      "works in machine learning and computer vision. Catie Chang is actually a neuroscientist \n",
      "who applies machine learning algorithms to try to understand the human brain. Tom Do \n",
      "is another PhD student, works in computational biology and in sort of the basic \n",
      "fundamentals of human learning. Zico Kolter is the head TA — he's head TA two years \n",
      "in a row now — works in machine learning a nd applies them to a bunch of robots. And \n",
      "Daniel Ramage is — I guess he's not here  — Daniel applies l earning algorithms to \n",
      "problems in natural language processing.  \n",
      "So you'll get to know the TAs and me much better throughout this quarter, but just from \n",
      "the sorts of things the TA's do, I hope you can already tell that machine learning is a \n",
      "highly interdisciplinary topic in which just the TAs find learning algorithms to problems \n",
      "in computer vision and biology and robots and language. And machine learning is one of \n",
      "those things that has and is having a large impact on many applications.  \n",
      "So just in my own daily work, I actually frequently end up talking to people like \n",
      "helicopter pilots to biologists to people in computer systems or databases to economists \n",
      "and sort of also an unending stream of people from industry coming to Stanford \n",
      "interested in applying machine learning methods to their own problems.  \n",
      "So yeah, this is fun. A couple of weeks ago, a student actually forwarded to me an article \n",
      "in \"Computer World\" about the 12 IT skills that employers can't say no to. So it's about \n",
      "sort of the 12 most desirable skills in all of IT and all of information technology, and \n",
      "topping the list was actually machine learning. So I think this is a good time to be \n",
      "learning this stuff and learning algorithms and having a large impact on many segments \n",
      "of science and industry.  \n",
      "I'm actually curious about something. Learning algorithms is one of the things that \n",
      "touches many areas of science and industries, and I'm just kind of curious. How many \n",
      "people here are computer science majors, are in the computer science department? Okay. \n",
      "About half of you. How many people are from EE? Oh, okay, maybe about a fifth. How' metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': 'MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31441672-d162-48b5-82dd-cfd017073e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
       " 'creator': 'PScript5.dll Version 5.2.2',\n",
       " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
       " 'author': '',\n",
       " 'moddate': '2008-07-11T11:25:23-07:00',\n",
       " 'title': '',\n",
       " 'source': 'MachineLearning-Lecture01.pdf',\n",
       " 'total_pages': 22,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a65662e3-52ee-4f66-b66f-71fce469b04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MachineLearning-Lecture01  \\nInstructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is just spend a little time going over the logistics \\nof the class, and then we\\'ll start to talk a bit about machine learning.  \\nBy way of introduction, my name\\'s Andrew Ng and I\\'ll be instructor for this class. And so \\nI personally work in machine learning, and I\\'ve worked on it for about 15 years now, and \\nI actually think that machine learning is the most exciting field of all the computer \\nsciences. So I\\'m actually always excited about teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thing in computer science, but \\nthe most exciting thing in all of human endeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learning and all aspects of machine learning. Paul Baumstarck \\nworks in machine learning and computer vision. Catie Chang is actually a neuroscientist \\nwho applies machine learning algorithms to try to understand the human brain. Tom Do \\nis another PhD student, works in computational biology and in sort of the basic \\nfundamentals of human learning. Zico Kolter is the head TA — he\\'s head TA two years \\nin a row now — works in machine learning a nd applies them to a bunch of robots. And \\nDaniel Ramage is — I guess he\\'s not here  — Daniel applies l earning algorithms to \\nproblems in natural language processing.  \\nSo you\\'ll get to know the TAs and me much better throughout this quarter, but just from \\nthe sorts of things the TA\\'s do, I hope you can already tell that machine learning is a \\nhighly interdisciplinary topic in which just the TAs find learning algorithms to problems \\nin computer vision and biology and robots and language. And machine learning is one of \\nthose things that has and is having a large impact on many applications.  \\nSo just in my own daily work, I actually frequently end up talking to people like \\nhelicopter pilots to biologists to people in computer systems or databases to economists \\nand sort of also an unending stream of people from industry coming to Stanford \\ninterested in applying machine learning methods to their own problems.  \\nSo yeah, this is fun. A couple of weeks ago, a student actually forwarded to me an article \\nin \"Computer World\" about the 12 IT skills that employers can\\'t say no to. So it\\'s about \\nsort of the 12 most desirable skills in all of IT and all of information technology, and \\ntopping the list was actually machine learning. So I think this is a good time to be \\nlearning this stuff and learning algorithms and having a large impact on many segments \\nof science and industry.  \\nI\\'m actually curious about something. Learning algorithms is one of the things that \\ntouches many areas of science and industries, and I\\'m just kind of curious. How many \\npeople here are computer science majors, are in the computer science department? Okay. \\nAbout half of you. How many people are from EE? Oh, okay, maybe about a fifth. How'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e4cf351-ce88-472d-91e2-a4e949dc4244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
      " 'creator': 'PScript5.dll Version 5.2.2',\n",
      " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
      " 'author': '',\n",
      " 'moddate': '2008-07-11T11:25:23-07:00',\n",
      " 'title': '',\n",
      " 'source': 'MachineLearning-Lecture01.pdf',\n",
      " 'total_pages': 22,\n",
      " 'page': 0,\n",
      " 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pp(pages[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc602c0c-f0e9-412b-bfe2-179013f8f118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_yt_dlp\n",
      "  Using cached langchain_yt_dlp-0.0.8-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting yt-dlp (from langchain_yt_dlp)\n",
      "  Downloading yt_dlp-2025.9.23-py3-none-any.whl.metadata (176 kB)\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.13/site-packages (from langchain_yt_dlp) (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (0.4.30)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (2.11.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->langchain_yt_dlp) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->langchain_yt_dlp) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->langchain_yt_dlp) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain->langchain_yt_dlp) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain->langchain_yt_dlp) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain->langchain_yt_dlp) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain->langchain_yt_dlp) (2025.8.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain->langchain_yt_dlp) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain->langchain_yt_dlp) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain->langchain_yt_dlp) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain->langchain_yt_dlp) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->langchain_yt_dlp) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->langchain_yt_dlp) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->langchain_yt_dlp) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->langchain_yt_dlp) (1.3.1)\n",
      "Using cached langchain_yt_dlp-0.0.8-py3-none-any.whl (4.8 kB)\n",
      "Downloading yt_dlp-2025.9.23-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: yt-dlp, langchain_yt_dlp\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [langchain_yt_dlp]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain_yt_dlp-0.0.8 yt-dlp-2025.9.23\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc7a9e8d-3024-41b7-bbef-6e17d41c41f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_yt_dlp.youtube_loader import YoutubeLoaderDL\n",
    "\n",
    "# Basic transcript loading\n",
    "loader = YoutubeLoaderDL.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\", add_video_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9154a46-85f8-4858-accf-4cecc3b5a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "251ec9b2-886c-4479-86a4-48b32a74473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f2b6543-361d-4251-b286-3029788839c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f24a3388-06fd-4dd9-9fee-f103eee591f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=' ' metadata={'source': 'dQw4w9WgXcQ', 'title': 'Rick Astley - Never Gonna Give You Up (Official Video) (4K Remaster)', 'description': 'The official video for “Never Gonna Give You Up” by Rick Astley. \\n\\nNever: The Autobiography 📚 OUT NOW! \\nFollow this link to get your copy and listen to Rick’s ‘Never’ playlist ❤️ #RickAstleyNever\\nhttps://linktr.ee/rickastleynever\\n\\n“Never Gonna Give You Up” was a global smash on its release in July 1987, topping the charts in 25 countries including Rick’s native UK and the US Billboard Hot 100.  It also won the Brit Award for Best single in 1988. Stock Aitken and Waterman wrote and produced the track which was the lead-off single and lead track from Rick’s debut LP “Whenever You Need Somebody”.  The album was itself a UK number one and would go on to sell over 15 million copies worldwide.\\n\\nThe legendary video was directed by Simon West – who later went on to make Hollywood blockbusters such as Con Air, Lara Croft – Tomb Raider and The Expendables 2.  The video passed the 1bn YouTube views milestone on 28 July 2021.\\n\\nSubscribe to the official Rick Astley YouTube channel: https://RickAstley.lnk.to/YTSubID\\n\\nFollow Rick Astley:\\nFacebook: https://RickAstley.lnk.to/FBFollowID \\nTwitter: https://RickAstley.lnk.to/TwitterID \\nInstagram: https://RickAstley.lnk.to/InstagramID \\nWebsite: https://RickAstley.lnk.to/storeID \\nTikTok: https://RickAstley.lnk.to/TikTokID\\n\\nListen to Rick Astley:\\nSpotify: https://RickAstley.lnk.to/SpotifyID \\nApple Music: https://RickAstley.lnk.to/AppleMusicID \\nAmazon Music: https://RickAstley.lnk.to/AmazonMusicID \\nDeezer: https://RickAstley.lnk.to/DeezerID \\n\\nLyrics:\\nWe’re no strangers to love\\nYou know the rules and so do I\\nA full commitment’s what I’m thinking of\\nYou wouldn’t get this from any other guy\\n\\nI just wanna tell you how I’m feeling\\nGotta make you understand\\n\\nNever gonna give you up\\nNever gonna let you down\\nNever gonna run around and desert you\\nNever gonna make you cry\\nNever gonna say goodbye\\nNever gonna tell a lie and hurt you\\n\\nWe’ve known each other for so long\\nYour heart’s been aching but you’re too shy to say it\\nInside we both know what’s been going on\\nWe know the game and we’re gonna play it\\n\\nAnd if you ask me how I’m feeling\\nDon’t tell me you’re too blind to see\\n\\nNever gonna give you up\\nNever gonna let you down\\nNever gonna run around and desert you\\nNever gonna make you cry\\nNever gonna say goodbye\\nNever gonna tell a lie and hurt you\\n\\n#RickAstley #NeverGonnaGiveYouUp #WheneverYouNeedSomebody #OfficialMusicVideo', 'view_count': 1696256619, 'publish_date': '2009-10-25', 'length': 213, 'author': 'Rick Astley', 'channel_id': 'UCuAXFkgsw1L7xaCfnd5JJOw', 'webpage_url': 'https://www.youtube.com/watch?v=dQw4w9WgXcQ'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3af980bb-7785-4df3-90e5-42cd1669b72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'dQw4w9WgXcQ',\n",
      " 'title': 'Rick Astley - Never Gonna Give You Up (Official Video) (4K '\n",
      "          'Remaster)',\n",
      " 'description': 'The official video for “Never Gonna Give You Up” by Rick '\n",
      "                'Astley. \\n'\n",
      "                '\\n'\n",
      "                'Never: The Autobiography 📚 OUT NOW! \\n'\n",
      "                'Follow this link to get your copy and listen to Rick’s '\n",
      "                '‘Never’ playlist ❤️ #RickAstleyNever\\n'\n",
      "                'https://linktr.ee/rickastleynever\\n'\n",
      "                '\\n'\n",
      "                '“Never Gonna Give You Up” was a global smash on its release '\n",
      "                'in July 1987, topping the charts in 25 countries including '\n",
      "                'Rick’s native UK and the US Billboard Hot 100.  It also won '\n",
      "                'the Brit Award for Best single in 1988. Stock Aitken and '\n",
      "                'Waterman wrote and produced the track which was the lead-off '\n",
      "                'single and lead track from Rick’s debut LP “Whenever You Need '\n",
      "                'Somebody”.  The album was itself a UK number one and would go '\n",
      "                'on to sell over 15 million copies worldwide.\\n'\n",
      "                '\\n'\n",
      "                'The legendary video was directed by Simon West – who later '\n",
      "                'went on to make Hollywood blockbusters such as Con Air, Lara '\n",
      "                'Croft – Tomb Raider and The Expendables 2.  The video passed '\n",
      "                'the 1bn YouTube views milestone on 28 July 2021.\\n'\n",
      "                '\\n'\n",
      "                'Subscribe to the official Rick Astley YouTube channel: '\n",
      "                'https://RickAstley.lnk.to/YTSubID\\n'\n",
      "                '\\n'\n",
      "                'Follow Rick Astley:\\n'\n",
      "                'Facebook: https://RickAstley.lnk.to/FBFollowID \\n'\n",
      "                'Twitter: https://RickAstley.lnk.to/TwitterID \\n'\n",
      "                'Instagram: https://RickAstley.lnk.to/InstagramID \\n'\n",
      "                'Website: https://RickAstley.lnk.to/storeID \\n'\n",
      "                'TikTok: https://RickAstley.lnk.to/TikTokID\\n'\n",
      "                '\\n'\n",
      "                'Listen to Rick Astley:\\n'\n",
      "                'Spotify: https://RickAstley.lnk.to/SpotifyID \\n'\n",
      "                'Apple Music: https://RickAstley.lnk.to/AppleMusicID \\n'\n",
      "                'Amazon Music: https://RickAstley.lnk.to/AmazonMusicID \\n'\n",
      "                'Deezer: https://RickAstley.lnk.to/DeezerID \\n'\n",
      "                '\\n'\n",
      "                'Lyrics:\\n'\n",
      "                'We’re no strangers to love\\n'\n",
      "                'You know the rules and so do I\\n'\n",
      "                'A full commitment’s what I’m thinking of\\n'\n",
      "                'You wouldn’t get this from any other guy\\n'\n",
      "                '\\n'\n",
      "                'I just wanna tell you how I’m feeling\\n'\n",
      "                'Gotta make you understand\\n'\n",
      "                '\\n'\n",
      "                'Never gonna give you up\\n'\n",
      "                'Never gonna let you down\\n'\n",
      "                'Never gonna run around and desert you\\n'\n",
      "                'Never gonna make you cry\\n'\n",
      "                'Never gonna say goodbye\\n'\n",
      "                'Never gonna tell a lie and hurt you\\n'\n",
      "                '\\n'\n",
      "                'We’ve known each other for so long\\n'\n",
      "                'Your heart’s been aching but you’re too shy to say it\\n'\n",
      "                'Inside we both know what’s been going on\\n'\n",
      "                'We know the game and we’re gonna play it\\n'\n",
      "                '\\n'\n",
      "                'And if you ask me how I’m feeling\\n'\n",
      "                'Don’t tell me you’re too blind to see\\n'\n",
      "                '\\n'\n",
      "                'Never gonna give you up\\n'\n",
      "                'Never gonna let you down\\n'\n",
      "                'Never gonna run around and desert you\\n'\n",
      "                'Never gonna make you cry\\n'\n",
      "                'Never gonna say goodbye\\n'\n",
      "                'Never gonna tell a lie and hurt you\\n'\n",
      "                '\\n'\n",
      "                '#RickAstley #NeverGonnaGiveYouUp #WheneverYouNeedSomebody '\n",
      "                '#OfficialMusicVideo',\n",
      " 'view_count': 1696256619,\n",
      " 'publish_date': '2009-10-25',\n",
      " 'length': 213,\n",
      " 'author': 'Rick Astley',\n",
      " 'channel_id': 'UCuAXFkgsw1L7xaCfnd5JJOw',\n",
      " 'webpage_url': 'https://www.youtube.com/watch?v=dQw4w9WgXcQ'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pp(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94e5870c-acea-4022-a2e6-875149acf38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8084c75-2dcf-428e-be62-390f33377352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet  youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "410ce6d7-a4ac-4d4b-ab8c-afbcf7ff1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=QsYGlZkevEg\", add_video_info=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1de10853-e69e-4114-891f-81d8d83f0eca",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'YouTubeTranscriptApi' has no attribute 'list_transcripts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m documents = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Sanketana/GenAI-Foundations/sandbox/RAG/venv/lib/python3.13/site-packages/langchain_community/document_loaders/youtube.py:262\u001b[39m, in \u001b[36mYoutubeLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    259\u001b[39m     \u001b[38;5;28mself\u001b[39m._metadata.update(video_info)\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     transcript_list = \u001b[43mYouTubeTranscriptApi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_transcripts\u001b[49m(\u001b[38;5;28mself\u001b[39m.video_id)\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TranscriptsDisabled:\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'YouTubeTranscriptApi' has no attribute 'list_transcripts'"
     ]
    }
   ],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c84ea124-e13f-4506-a3f6-65899456425d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: youtube-transcript-api\n",
      "Version: 1.2.2\n",
      "Summary: This is an python API which allows you to get the transcripts/subtitles for a given YouTube video. It also works for automatically generated subtitles, supports translating subtitles and it does not require a headless browser, like other selenium based solutions do!\n",
      "Home-page: https://github.com/jdepoix/youtube-transcript-api\n",
      "Author: Jonas Depoix\n",
      "Author-email: jonas.depoix@web.de\n",
      "License: MIT\n",
      "Location: /Users/abhinav/Documents/Sanketana/GenAI-Foundations/sandbox/RAG/venv/lib/python3.13/site-packages\n",
      "Requires: defusedxml, requests\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70df390a-71e8-40e8-a9b9-d850e8fdaa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in ./venv/lib/python3.13/site-packages (1.2.2)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in ./venv/lib/python3.13/site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.13/site-packages (from youtube-transcript-api) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests->youtube-transcript-api) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests->youtube-transcript-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests->youtube-transcript-api) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests->youtube-transcript-api) (2025.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade youtube-transcript-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0812929-163f-4f93-9e57-3a8cab5590e5",
   "metadata": {},
   "source": [
    "## 2) Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965aee6d-cfd2-4f9a-9aef-b51ea9c65d06",
   "metadata": {},
   "source": [
    "1. Character Text Splitter\n",
    "2. Recusive Text Splitter\n",
    "3. Token Text splitter\n",
    "4. Markdown Text Splitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f3c9b82-b773-464e-abdc-eb3e1e9d9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5917fc0e-4c41-469f-87fa-277cf66fca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "text = \"\"\"Artificial Intelligence is changing the world. It is being used in healthcare, education, and entertainment. \n",
    "\n",
    "However, AI also raises ethical concerns. Bias, privacy, and misuse are important issues.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "421f6f0d-079b-4852-aa6d-12a6d7c5e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 50\n",
    "chunk_overlap = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a15c6066-56e5-41a4-8b40-cc126132aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 109, which is longer than the specified 50\n"
     ]
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap\n",
    ")\n",
    "\n",
    "documents = c_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9c504ac-929b-45da-8b62-3d2911216a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c98cd8a5-ffe8-4611-b355-2037326850a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "caf6cf5a-d1f4-4c41-be4d-fa2a44bf709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is changing the world. It\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "605124ce-195b-407d-b84a-69e656a5b654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However, AI also raises ethical concerns. Bias, privacy, and misuse are important issues.\n"
     ]
    }
   ],
   "source": [
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e81da92-e903-4794-845a-86c0b5df9ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is changing the world. It\n"
     ]
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap\n",
    ")\n",
    "documents = r_splitter.split_text(text)\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b0016f8-85d5-4288-9302-ed9a429c1955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d57bd6e-b9f4-4ba2-a1fb-c7661683db90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is changing the world. It\n",
      "world. It is being used in healthcare, education,\n",
      "and entertainment.\n",
      "However, AI also raises ethical concerns. Bias,\n",
      "Bias, privacy, and misuse are important issues.\n"
     ]
    }
   ],
   "source": [
    "for chunk in documents:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d618cb8c-517a-4be7-91dd-50d58635945b",
   "metadata": {},
   "source": [
    "## 3) Vectorstore and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3332357c-8b52-4255-97c5-e209d695275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 480\n",
      "drwxr-xr-x@  9 abhinav  staff    288 Sep 23 18:53 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 15 abhinav  staff    480 Sep 23 17:37 \u001b[34m..\u001b[m\u001b[m\n",
      "-rw-r--r--@  1 abhinav  staff    366 Sep 23 17:44 .env\n",
      "drwxr-xr-x@  3 abhinav  staff     96 Sep 23 17:50 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\n",
      "-rw-rw-r--@  1 abhinav  staff  64553 Sep 23 17:59 MachineLearning-Lecture01.pdf\n",
      "-rw-rw-r--@  1 abhinav  staff  54966 Sep 23 18:53 MachineLearning-Lecture02.pdf\n",
      "-rw-rw-r--@  1 abhinav  staff  57469 Sep 23 18:53 MachineLearning-Lecture03.pdf\n",
      "-rw-r--r--@  1 abhinav  staff  56469 Sep 23 18:53 RAG.ipynb\n",
      "drwxr-xr-x@  9 abhinav  staff    288 Sep 23 17:40 \u001b[34mvenv\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "000f01a2-5749-4071-b040-5888cff9e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    PyPDFLoader(\"MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "\n",
    "docs = []\n",
    "\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83ddeaff-4759-43e7-b792-ee6b1f19646c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef1ef88f-0bf8-41cc-9dde-d8fd657824d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500, \n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d38d3d3-7254-414e-8764-bb636692730c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2eab49b3-8aaf-437e-9120-a9e1ea5f013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of the class, and then we'll start to talk a bit about machine learning.  \n",
      "By way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \n",
      "I personally work in machine learning, and I've worked on it for about 15 years now, and \n",
      "I actually think that machine learning is the most exciting field of all the computer \n",
      "sciences. So I'm actually always excited about teaching this class. Sometimes I actually \n",
      "think that machine learning is not only the most exciting thing in computer science, but \n",
      "the most exciting thing in all of human endeavor, so maybe a little bias there.  \n",
      "I also want to introduce the TAs, who are all graduate students doing research in or \n",
      "related to the machine learning and all aspects of machine learning. Paul Baumstarck \n",
      "works in machine learning and computer vision. Catie Chang is actually a neuroscientist \n",
      "who applies machine learning algorithms to try to understand the human brain. Tom Do \n",
      "is another PhD student, works in computational biology and in sort of the basic \n",
      "fundamentals of human learning. Zico Kolter is the head TA — he's head TA two years \n",
      "in a row now — works in machine learning a nd applies them to a bunch of robots. And \n",
      "Daniel Ramage is — I guess he's not here  — Daniel applies l earning algorithms to \n",
      "problems in natural language processing.  \n",
      "So you'll get to know the TAs and me much better throughout this quarter, but just from \n",
      "the sorts of things the TA's do, I hope you can already tell that machine learning is a \n",
      "highly interdisciplinary topic in which just the TAs find learning algorithms to problems \n",
      "in computer vision and biology and robots and language. And machine learning is one of \n",
      "those things that has and is having a large impact on many applications.  \n",
      "So just in my own daily work, I actually frequently end up talking to people like \n",
      "helicopter pilots to biologists to people in computer systems or databases to economists \n",
      "and sort of also an unending stream of people from industry coming to Stanford \n",
      "interested in applying machine learning methods to their own problems.  \n",
      "So yeah, this is fun. A couple of weeks ago, a student actually forwarded to me an article \n",
      "in \"Computer World\" about the 12 IT skills that employers can't say no to. So it's about \n",
      "sort of the 12 most desirable skills in all of IT and all of information technology, and \n",
      "topping the list was actually machine learning. So I think this is a good time to be \n",
      "learning this stuff and learning algorithms and having a large impact on many segments \n",
      "of science and industry.  \n",
      "I'm actually curious about something. Learning algorithms is one of the things that \n",
      "touches many areas of science and industries, and I'm just kind of curious. How many \n",
      "people here are computer science majors, are in the computer science department? Okay. \n",
      "About half of you. How many people are from EE? Oh, okay, maybe about a fifth. How\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ff24631-4f5f-4952-b195-cf8457e2cda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098\n"
     ]
    }
   ],
   "source": [
    "print(len(splits[3].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c5e45-d460-4c15-b7ba-1ed1da109286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
