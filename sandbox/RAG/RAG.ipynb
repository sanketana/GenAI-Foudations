{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158910a7-e43c-48f3-824a-0d16de6d165f",
   "metadata": {},
   "source": [
    "Basic RAG Components\n",
    "1. Loading\n",
    "2. Splitting\n",
    "3. Vectorstore and Embedding\n",
    "4. Retrieval\n",
    "5. Q/A generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59391e0-68fc-4647-a8e0-46a97408360a",
   "metadata": {},
   "source": [
    "1. Text Loader\n",
    "2. CSV Loader\n",
    "3. PDF Loader\n",
    "4. Youtube Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a207eadd-f13d-44d9-b31d-6954c222e464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01.pdf \u001b[34mvenv\u001b[m\u001b[m\n",
      "RAG.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7216c4f-2072-43ba-aa1c-84795aa43104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Using cached langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.30-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached sqlalchemy-2.0.43-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached orjson-3.11.3-cp313-cp313-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached zstandard-0.25.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Using cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached sqlalchemy-2.0.43-cp313-cp313-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading langsmith-0.4.30-py3-none-any.whl (386 kB)\n",
      "Using cached orjson-3.11.3-cp313-cp313-macosx_15_0_arm64.whl (127 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached zstandard-0.25.0-cp313-cp313-macosx_11_0_arm64.whl (640 kB)\n",
      "Installing collected packages: zstandard, typing-inspection, tenacity, SQLAlchemy, pydantic-core, orjson, jsonpatch, annotated-types, requests-toolbelt, pydantic, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/14\u001b[0m [langchain][0m \u001b[32m13/14\u001b[0m [langchain]core]h]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.43 annotated-types-0.7.0 jsonpatch-1.33 langchain-0.3.27 langchain-core-0.3.76 langchain-text-splitters-0.3.11 langsmith-0.4.30 orjson-3.11.3 pydantic-2.11.9 pydantic-core-2.33.2 requests-toolbelt-1.0.0 tenacity-9.1.2 typing-inspection-0.4.1 zstandard-0.25.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.3.76)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2.32.5 in ./venv/lib/python3.13/site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Using cached aiohttp-3.12.15-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in ./venv/lib/python3.13/site-packages (from langchain-community) (0.4.30)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=2.1.0 (from langchain-community)\n",
      "  Using cached numpy-2.3.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.7.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.6.4-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.3.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.20.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./venv/lib/python3.13/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.4.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Using cached langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "Using cached aiohttp-3.12.15-cp313-cp313-macosx_11_0_arm64.whl (466 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.6.4-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.1-cp313-cp313-macosx_11_0_arm64.whl (88 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached frozenlist-1.7.0-cp313-cp313-macosx_11_0_arm64.whl (45 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached numpy-2.3.3-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Using cached propcache-0.3.2-cp313-cp313-macosx_11_0_arm64.whl (41 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [langchain-community] \u001b[32m15/16\u001b[0m [langchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 dataclasses-json-0.6.7 frozenlist-1.7.0 httpx-sse-0.4.1 langchain-community-0.3.29 marshmallow-3.26.1 multidict-6.6.4 mypy-extensions-1.1.0 numpy-2.3.3 propcache-0.3.2 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0 yarl-1.20.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.1.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Downloading pypdf-6.1.0-py3-none-any.whl (322 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-6.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-community\n",
    "!pip install pypdf\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b4fdd46-5f09-41ef-a5c6-cd134be39c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"MachineLearning-Lecture01.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54325548-dca5-4c26-83eb-b313438c8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6775fbcd-2962-43a7-81f0-7af9981e7862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "466d3096-beff-4563-87af-11c14ebd7deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbd572cf-8f18-4db6-8a5d-c2cc391e2072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67322faf-2074-461a-b15c-d502fd3e7486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of the class, and then we'll start to talk a bit about machine learning.  \n",
      "By way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \n",
      "I personally work in machine learning, and I've worked on it for about 15 years now, and \n",
      "I actually think that machine learning is the most exciting field of all the computer \n",
      "sciences. So I'm actually always excited about teaching this class. Sometimes I actually \n",
      "think that machine learning is not only the most exciting thing in computer science, but \n",
      "the most exciting thing in all of human endeavor, so maybe a little bias there.  \n",
      "I also want to introduce the TAs, who are all graduate students doing research in or \n",
      "related to the machine learning and all aspects of machine learning. Paul Baumstarck \n",
      "works in machine learning and computer vision. Catie Chang is actually a neuroscientist \n",
      "who applies machine learning algorithms to try to understand the human brain. Tom Do \n",
      "is another PhD student, works in computational biology and in sort of the basic \n",
      "fundamentals of human learning. Zico Kolter is the head TA — he's head TA two years \n",
      "in a row now — works in machine learning a nd applies them to a bunch of robots. And \n",
      "Daniel Ramage is — I guess he's not here  — Daniel applies l earning algorithms to \n",
      "problems in natural language processing.  \n",
      "So you'll get to know the TAs and me much better throughout this quarter, but just from \n",
      "the sorts of things the TA's do, I hope you can already tell that machine learning is a \n",
      "highly interdisciplinary topic in which just the TAs find learning algorithms to problems \n",
      "in computer vision and biology and robots and language. And machine learning is one of \n",
      "those things that has and is having a large impact on many applications.  \n",
      "So just in my own daily work, I actually frequently end up talking to people like \n",
      "helicopter pilots to biologists to people in computer systems or databases to economists \n",
      "and sort of also an unending stream of people from industry coming to Stanford \n",
      "interested in applying machine learning methods to their own problems.  \n",
      "So yeah, this is fun. A couple of weeks ago, a student actually forwarded to me an article \n",
      "in \"Computer World\" about the 12 IT skills that employers can't say no to. So it's about \n",
      "sort of the 12 most desirable skills in all of IT and all of information technology, and \n",
      "topping the list was actually machine learning. So I think this is a good time to be \n",
      "learning this stuff and learning algorithms and having a large impact on many segments \n",
      "of science and industry.  \n",
      "I'm actually curious about something. Learning algorithms is one of the things that \n",
      "touches many areas of science and industries, and I'm just kind of curious. How many \n",
      "people here are computer science majors, are in the computer science department? Okay. \n",
      "About half of you. How many people are from EE? Oh, okay, maybe about a fifth. How' metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2008-07-11T11:25:23-07:00', 'author': '', 'moddate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': 'MachineLearning-Lecture01.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31441672-d162-48b5-82dd-cfd017073e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
       " 'creator': 'PScript5.dll Version 5.2.2',\n",
       " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
       " 'author': '',\n",
       " 'moddate': '2008-07-11T11:25:23-07:00',\n",
       " 'title': '',\n",
       " 'source': 'MachineLearning-Lecture01.pdf',\n",
       " 'total_pages': 22,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a65662e3-52ee-4f66-b66f-71fce469b04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MachineLearning-Lecture01  \\nInstructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is just spend a little time going over the logistics \\nof the class, and then we\\'ll start to talk a bit about machine learning.  \\nBy way of introduction, my name\\'s Andrew Ng and I\\'ll be instructor for this class. And so \\nI personally work in machine learning, and I\\'ve worked on it for about 15 years now, and \\nI actually think that machine learning is the most exciting field of all the computer \\nsciences. So I\\'m actually always excited about teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thing in computer science, but \\nthe most exciting thing in all of human endeavor, so maybe a little bias there.  \\nI also want to introduce the TAs, who are all graduate students doing research in or \\nrelated to the machine learning and all aspects of machine learning. Paul Baumstarck \\nworks in machine learning and computer vision. Catie Chang is actually a neuroscientist \\nwho applies machine learning algorithms to try to understand the human brain. Tom Do \\nis another PhD student, works in computational biology and in sort of the basic \\nfundamentals of human learning. Zico Kolter is the head TA — he\\'s head TA two years \\nin a row now — works in machine learning a nd applies them to a bunch of robots. And \\nDaniel Ramage is — I guess he\\'s not here  — Daniel applies l earning algorithms to \\nproblems in natural language processing.  \\nSo you\\'ll get to know the TAs and me much better throughout this quarter, but just from \\nthe sorts of things the TA\\'s do, I hope you can already tell that machine learning is a \\nhighly interdisciplinary topic in which just the TAs find learning algorithms to problems \\nin computer vision and biology and robots and language. And machine learning is one of \\nthose things that has and is having a large impact on many applications.  \\nSo just in my own daily work, I actually frequently end up talking to people like \\nhelicopter pilots to biologists to people in computer systems or databases to economists \\nand sort of also an unending stream of people from industry coming to Stanford \\ninterested in applying machine learning methods to their own problems.  \\nSo yeah, this is fun. A couple of weeks ago, a student actually forwarded to me an article \\nin \"Computer World\" about the 12 IT skills that employers can\\'t say no to. So it\\'s about \\nsort of the 12 most desirable skills in all of IT and all of information technology, and \\ntopping the list was actually machine learning. So I think this is a good time to be \\nlearning this stuff and learning algorithms and having a large impact on many segments \\nof science and industry.  \\nI\\'m actually curious about something. Learning algorithms is one of the things that \\ntouches many areas of science and industries, and I\\'m just kind of curious. How many \\npeople here are computer science majors, are in the computer science department? Okay. \\nAbout half of you. How many people are from EE? Oh, okay, maybe about a fifth. How'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e4cf351-ce88-472d-91e2-a4e949dc4244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Acrobat Distiller 8.1.0 (Windows)',\n",
      " 'creator': 'PScript5.dll Version 5.2.2',\n",
      " 'creationdate': '2008-07-11T11:25:23-07:00',\n",
      " 'author': '',\n",
      " 'moddate': '2008-07-11T11:25:23-07:00',\n",
      " 'title': '',\n",
      " 'source': 'MachineLearning-Lecture01.pdf',\n",
      " 'total_pages': 22,\n",
      " 'page': 0,\n",
      " 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pp(pages[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc602c0c-f0e9-412b-bfe2-179013f8f118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_yt_dlp\n",
      "  Using cached langchain_yt_dlp-0.0.8-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting yt-dlp (from langchain_yt_dlp)\n",
      "  Downloading yt_dlp-2025.9.23-py3-none-any.whl.metadata (176 kB)\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.13/site-packages (from langchain_yt_dlp) (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (0.4.30)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (2.11.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.13/site-packages (from langchain->langchain_yt_dlp) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain->langchain_yt_dlp) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->langchain_yt_dlp) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->langchain_yt_dlp) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain->langchain_yt_dlp) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain->langchain_yt_dlp) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain->langchain_yt_dlp) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain->langchain_yt_dlp) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests<3,>=2->langchain->langchain_yt_dlp) (2025.8.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain->langchain_yt_dlp) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain->langchain_yt_dlp) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain->langchain_yt_dlp) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain->langchain_yt_dlp) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->langchain_yt_dlp) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->langchain_yt_dlp) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->langchain_yt_dlp) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain->langchain_yt_dlp) (1.3.1)\n",
      "Using cached langchain_yt_dlp-0.0.8-py3-none-any.whl (4.8 kB)\n",
      "Downloading yt_dlp-2025.9.23-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: yt-dlp, langchain_yt_dlp\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [langchain_yt_dlp]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain_yt_dlp-0.0.8 yt-dlp-2025.9.23\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_yt_dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc7a9e8d-3024-41b7-bbef-6e17d41c41f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_yt_dlp.youtube_loader import YoutubeLoaderDL\n",
    "\n",
    "# Basic transcript loading\n",
    "loader = YoutubeLoaderDL.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\", add_video_info=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9154a46-85f8-4858-accf-4cecc3b5a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "251ec9b2-886c-4479-86a4-48b32a74473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f2b6543-361d-4251-b286-3029788839c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f24a3388-06fd-4dd9-9fee-f103eee591f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=' ' metadata={'source': 'dQw4w9WgXcQ', 'title': 'Rick Astley - Never Gonna Give You Up (Official Video) (4K Remaster)', 'description': 'The official video for “Never Gonna Give You Up” by Rick Astley. \\n\\nNever: The Autobiography 📚 OUT NOW! \\nFollow this link to get your copy and listen to Rick’s ‘Never’ playlist ❤️ #RickAstleyNever\\nhttps://linktr.ee/rickastleynever\\n\\n“Never Gonna Give You Up” was a global smash on its release in July 1987, topping the charts in 25 countries including Rick’s native UK and the US Billboard Hot 100.  It also won the Brit Award for Best single in 1988. Stock Aitken and Waterman wrote and produced the track which was the lead-off single and lead track from Rick’s debut LP “Whenever You Need Somebody”.  The album was itself a UK number one and would go on to sell over 15 million copies worldwide.\\n\\nThe legendary video was directed by Simon West – who later went on to make Hollywood blockbusters such as Con Air, Lara Croft – Tomb Raider and The Expendables 2.  The video passed the 1bn YouTube views milestone on 28 July 2021.\\n\\nSubscribe to the official Rick Astley YouTube channel: https://RickAstley.lnk.to/YTSubID\\n\\nFollow Rick Astley:\\nFacebook: https://RickAstley.lnk.to/FBFollowID \\nTwitter: https://RickAstley.lnk.to/TwitterID \\nInstagram: https://RickAstley.lnk.to/InstagramID \\nWebsite: https://RickAstley.lnk.to/storeID \\nTikTok: https://RickAstley.lnk.to/TikTokID\\n\\nListen to Rick Astley:\\nSpotify: https://RickAstley.lnk.to/SpotifyID \\nApple Music: https://RickAstley.lnk.to/AppleMusicID \\nAmazon Music: https://RickAstley.lnk.to/AmazonMusicID \\nDeezer: https://RickAstley.lnk.to/DeezerID \\n\\nLyrics:\\nWe’re no strangers to love\\nYou know the rules and so do I\\nA full commitment’s what I’m thinking of\\nYou wouldn’t get this from any other guy\\n\\nI just wanna tell you how I’m feeling\\nGotta make you understand\\n\\nNever gonna give you up\\nNever gonna let you down\\nNever gonna run around and desert you\\nNever gonna make you cry\\nNever gonna say goodbye\\nNever gonna tell a lie and hurt you\\n\\nWe’ve known each other for so long\\nYour heart’s been aching but you’re too shy to say it\\nInside we both know what’s been going on\\nWe know the game and we’re gonna play it\\n\\nAnd if you ask me how I’m feeling\\nDon’t tell me you’re too blind to see\\n\\nNever gonna give you up\\nNever gonna let you down\\nNever gonna run around and desert you\\nNever gonna make you cry\\nNever gonna say goodbye\\nNever gonna tell a lie and hurt you\\n\\n#RickAstley #NeverGonnaGiveYouUp #WheneverYouNeedSomebody #OfficialMusicVideo', 'view_count': 1696256619, 'publish_date': '2009-10-25', 'length': 213, 'author': 'Rick Astley', 'channel_id': 'UCuAXFkgsw1L7xaCfnd5JJOw', 'webpage_url': 'https://www.youtube.com/watch?v=dQw4w9WgXcQ'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3af980bb-7785-4df3-90e5-42cd1669b72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'dQw4w9WgXcQ',\n",
      " 'title': 'Rick Astley - Never Gonna Give You Up (Official Video) (4K '\n",
      "          'Remaster)',\n",
      " 'description': 'The official video for “Never Gonna Give You Up” by Rick '\n",
      "                'Astley. \\n'\n",
      "                '\\n'\n",
      "                'Never: The Autobiography 📚 OUT NOW! \\n'\n",
      "                'Follow this link to get your copy and listen to Rick’s '\n",
      "                '‘Never’ playlist ❤️ #RickAstleyNever\\n'\n",
      "                'https://linktr.ee/rickastleynever\\n'\n",
      "                '\\n'\n",
      "                '“Never Gonna Give You Up” was a global smash on its release '\n",
      "                'in July 1987, topping the charts in 25 countries including '\n",
      "                'Rick’s native UK and the US Billboard Hot 100.  It also won '\n",
      "                'the Brit Award for Best single in 1988. Stock Aitken and '\n",
      "                'Waterman wrote and produced the track which was the lead-off '\n",
      "                'single and lead track from Rick’s debut LP “Whenever You Need '\n",
      "                'Somebody”.  The album was itself a UK number one and would go '\n",
      "                'on to sell over 15 million copies worldwide.\\n'\n",
      "                '\\n'\n",
      "                'The legendary video was directed by Simon West – who later '\n",
      "                'went on to make Hollywood blockbusters such as Con Air, Lara '\n",
      "                'Croft – Tomb Raider and The Expendables 2.  The video passed '\n",
      "                'the 1bn YouTube views milestone on 28 July 2021.\\n'\n",
      "                '\\n'\n",
      "                'Subscribe to the official Rick Astley YouTube channel: '\n",
      "                'https://RickAstley.lnk.to/YTSubID\\n'\n",
      "                '\\n'\n",
      "                'Follow Rick Astley:\\n'\n",
      "                'Facebook: https://RickAstley.lnk.to/FBFollowID \\n'\n",
      "                'Twitter: https://RickAstley.lnk.to/TwitterID \\n'\n",
      "                'Instagram: https://RickAstley.lnk.to/InstagramID \\n'\n",
      "                'Website: https://RickAstley.lnk.to/storeID \\n'\n",
      "                'TikTok: https://RickAstley.lnk.to/TikTokID\\n'\n",
      "                '\\n'\n",
      "                'Listen to Rick Astley:\\n'\n",
      "                'Spotify: https://RickAstley.lnk.to/SpotifyID \\n'\n",
      "                'Apple Music: https://RickAstley.lnk.to/AppleMusicID \\n'\n",
      "                'Amazon Music: https://RickAstley.lnk.to/AmazonMusicID \\n'\n",
      "                'Deezer: https://RickAstley.lnk.to/DeezerID \\n'\n",
      "                '\\n'\n",
      "                'Lyrics:\\n'\n",
      "                'We’re no strangers to love\\n'\n",
      "                'You know the rules and so do I\\n'\n",
      "                'A full commitment’s what I’m thinking of\\n'\n",
      "                'You wouldn’t get this from any other guy\\n'\n",
      "                '\\n'\n",
      "                'I just wanna tell you how I’m feeling\\n'\n",
      "                'Gotta make you understand\\n'\n",
      "                '\\n'\n",
      "                'Never gonna give you up\\n'\n",
      "                'Never gonna let you down\\n'\n",
      "                'Never gonna run around and desert you\\n'\n",
      "                'Never gonna make you cry\\n'\n",
      "                'Never gonna say goodbye\\n'\n",
      "                'Never gonna tell a lie and hurt you\\n'\n",
      "                '\\n'\n",
      "                'We’ve known each other for so long\\n'\n",
      "                'Your heart’s been aching but you’re too shy to say it\\n'\n",
      "                'Inside we both know what’s been going on\\n'\n",
      "                'We know the game and we’re gonna play it\\n'\n",
      "                '\\n'\n",
      "                'And if you ask me how I’m feeling\\n'\n",
      "                'Don’t tell me you’re too blind to see\\n'\n",
      "                '\\n'\n",
      "                'Never gonna give you up\\n'\n",
      "                'Never gonna let you down\\n'\n",
      "                'Never gonna run around and desert you\\n'\n",
      "                'Never gonna make you cry\\n'\n",
      "                'Never gonna say goodbye\\n'\n",
      "                'Never gonna tell a lie and hurt you\\n'\n",
      "                '\\n'\n",
      "                '#RickAstley #NeverGonnaGiveYouUp #WheneverYouNeedSomebody '\n",
      "                '#OfficialMusicVideo',\n",
      " 'view_count': 1696256619,\n",
      " 'publish_date': '2009-10-25',\n",
      " 'length': 213,\n",
      " 'author': 'Rick Astley',\n",
      " 'channel_id': 'UCuAXFkgsw1L7xaCfnd5JJOw',\n",
      " 'webpage_url': 'https://www.youtube.com/watch?v=dQw4w9WgXcQ'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pp(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94e5870c-acea-4022-a2e6-875149acf38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8084c75-2dcf-428e-be62-390f33377352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet  youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "410ce6d7-a4ac-4d4b-ab8c-afbcf7ff1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=QsYGlZkevEg\", add_video_info=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1de10853-e69e-4114-891f-81d8d83f0eca",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'YouTubeTranscriptApi' has no attribute 'list_transcripts'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m documents = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Sanketana/GenAI-Foundations/sandbox/RAG/venv/lib/python3.13/site-packages/langchain_community/document_loaders/youtube.py:262\u001b[39m, in \u001b[36mYoutubeLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    259\u001b[39m     \u001b[38;5;28mself\u001b[39m._metadata.update(video_info)\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     transcript_list = \u001b[43mYouTubeTranscriptApi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_transcripts\u001b[49m(\u001b[38;5;28mself\u001b[39m.video_id)\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TranscriptsDisabled:\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[31mAttributeError\u001b[39m: type object 'YouTubeTranscriptApi' has no attribute 'list_transcripts'"
     ]
    }
   ],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c84ea124-e13f-4506-a3f6-65899456425d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: youtube-transcript-api\n",
      "Version: 1.2.2\n",
      "Summary: This is an python API which allows you to get the transcripts/subtitles for a given YouTube video. It also works for automatically generated subtitles, supports translating subtitles and it does not require a headless browser, like other selenium based solutions do!\n",
      "Home-page: https://github.com/jdepoix/youtube-transcript-api\n",
      "Author: Jonas Depoix\n",
      "Author-email: jonas.depoix@web.de\n",
      "License: MIT\n",
      "Location: /Users/abhinav/Documents/Sanketana/GenAI-Foundations/sandbox/RAG/venv/lib/python3.13/site-packages\n",
      "Requires: defusedxml, requests\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70df390a-71e8-40e8-a9b9-d850e8fdaa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in ./venv/lib/python3.13/site-packages (1.2.2)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in ./venv/lib/python3.13/site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.13/site-packages (from youtube-transcript-api) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests->youtube-transcript-api) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests->youtube-transcript-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests->youtube-transcript-api) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests->youtube-transcript-api) (2025.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade youtube-transcript-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0812929-163f-4f93-9e57-3a8cab5590e5",
   "metadata": {},
   "source": [
    "## 2) Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965aee6d-cfd2-4f9a-9aef-b51ea9c65d06",
   "metadata": {},
   "source": [
    "1. Character Text Splitter\n",
    "2. Recusive Text Splitter\n",
    "3. Token Text splitter\n",
    "4. Markdown Text Splitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f3c9b82-b773-464e-abdc-eb3e1e9d9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5917fc0e-4c41-469f-87fa-277cf66fca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text\n",
    "text = \"\"\"Artificial Intelligence is changing the world. It is being used in healthcare, education, and entertainment. \n",
    "\n",
    "However, AI also raises ethical concerns. Bias, privacy, and misuse are important issues.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "421f6f0d-079b-4852-aa6d-12a6d7c5e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 50\n",
    "chunk_overlap = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a15c6066-56e5-41a4-8b40-cc126132aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 109, which is longer than the specified 50\n"
     ]
    }
   ],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap\n",
    ")\n",
    "\n",
    "documents = c_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9c504ac-929b-45da-8b62-3d2911216a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c98cd8a5-ffe8-4611-b355-2037326850a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "caf6cf5a-d1f4-4c41-be4d-fa2a44bf709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is changing the world. It\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "605124ce-195b-407d-b84a-69e656a5b654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However, AI also raises ethical concerns. Bias, privacy, and misuse are important issues.\n"
     ]
    }
   ],
   "source": [
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e81da92-e903-4794-845a-86c0b5df9ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is changing the world. It\n"
     ]
    }
   ],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap\n",
    ")\n",
    "documents = r_splitter.split_text(text)\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b0016f8-85d5-4288-9302-ed9a429c1955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d57bd6e-b9f4-4ba2-a1fb-c7661683db90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is changing the world. It\n",
      "world. It is being used in healthcare, education,\n",
      "and entertainment.\n",
      "However, AI also raises ethical concerns. Bias,\n",
      "Bias, privacy, and misuse are important issues.\n"
     ]
    }
   ],
   "source": [
    "for chunk in documents:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d618cb8c-517a-4be7-91dd-50d58635945b",
   "metadata": {},
   "source": [
    "## 3) Vectorstore and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3332357c-8b52-4255-97c5-e209d695275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 480\n",
      "drwxr-xr-x@  9 abhinav  staff    288 Sep 23 18:53 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 15 abhinav  staff    480 Sep 23 17:37 \u001b[34m..\u001b[m\u001b[m\n",
      "-rw-r--r--@  1 abhinav  staff    366 Sep 23 17:44 .env\n",
      "drwxr-xr-x@  3 abhinav  staff     96 Sep 23 17:50 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\n",
      "-rw-rw-r--@  1 abhinav  staff  64553 Sep 23 17:59 MachineLearning-Lecture01.pdf\n",
      "-rw-rw-r--@  1 abhinav  staff  54966 Sep 23 18:53 MachineLearning-Lecture02.pdf\n",
      "-rw-rw-r--@  1 abhinav  staff  57469 Sep 23 18:53 MachineLearning-Lecture03.pdf\n",
      "-rw-r--r--@  1 abhinav  staff  56469 Sep 23 18:53 RAG.ipynb\n",
      "drwxr-xr-x@  9 abhinav  staff    288 Sep 23 17:40 \u001b[34mvenv\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "000f01a2-5749-4071-b040-5888cff9e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    PyPDFLoader(\"MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "\n",
    "docs = []\n",
    "\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83ddeaff-4759-43e7-b792-ee6b1f19646c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef1ef88f-0bf8-41cc-9dde-d8fd657824d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500, \n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d38d3d3-7254-414e-8764-bb636692730c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2eab49b3-8aaf-437e-9120-a9e1ea5f013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of the class, and then we'll start to talk a bit about machine learning.  \n",
      "By way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \n",
      "I personally work in machine learning, and I've worked on it for about 15 years now, and \n",
      "I actually think that machine learning is the most exciting field of all the computer \n",
      "sciences. So I'm actually always excited about teaching this class. Sometimes I actually \n",
      "think that machine learning is not only the most exciting thing in computer science, but \n",
      "the most exciting thing in all of human endeavor, so maybe a little bias there.  \n",
      "I also want to introduce the TAs, who are all graduate students doing research in or \n",
      "related to the machine learning and all aspects of machine learning. Paul Baumstarck \n",
      "works in machine learning and computer vision. Catie Chang is actually a neuroscientist \n",
      "who applies machine learning algorithms to try to understand the human brain. Tom Do \n",
      "is another PhD student, works in computational biology and in sort of the basic \n",
      "fundamentals of human learning. Zico Kolter is the head TA — he's head TA two years \n",
      "in a row now — works in machine learning a nd applies them to a bunch of robots. And \n",
      "Daniel Ramage is — I guess he's not here  — Daniel applies l earning algorithms to \n",
      "problems in natural language processing.  \n",
      "So you'll get to know the TAs and me much better throughout this quarter, but just from \n",
      "the sorts of things the TA's do, I hope you can already tell that machine learning is a \n",
      "highly interdisciplinary topic in which just the TAs find learning algorithms to problems \n",
      "in computer vision and biology and robots and language. And machine learning is one of \n",
      "those things that has and is having a large impact on many applications.  \n",
      "So just in my own daily work, I actually frequently end up talking to people like \n",
      "helicopter pilots to biologists to people in computer systems or databases to economists \n",
      "and sort of also an unending stream of people from industry coming to Stanford \n",
      "interested in applying machine learning methods to their own problems.  \n",
      "So yeah, this is fun. A couple of weeks ago, a student actually forwarded to me an article \n",
      "in \"Computer World\" about the 12 IT skills that employers can't say no to. So it's about \n",
      "sort of the 12 most desirable skills in all of IT and all of information technology, and \n",
      "topping the list was actually machine learning. So I think this is a good time to be \n",
      "learning this stuff and learning algorithms and having a large impact on many segments \n",
      "of science and industry.  \n",
      "I'm actually curious about something. Learning algorithms is one of the things that \n",
      "touches many areas of science and industries, and I'm just kind of curious. How many \n",
      "people here are computer science majors, are in the computer science department? Okay. \n",
      "About half of you. How many people are from EE? Oh, okay, maybe about a fifth. How\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ff24631-4f5f-4952-b195-cf8457e2cda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098\n"
     ]
    }
   ],
   "source": [
    "print(len(splits[3].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1138dc87-2168-4d3b-a2db-b122f8ad1a04",
   "metadata": {},
   "source": [
    "## 3) Vectorstore and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c07638-a2dc-4635-95a1-d2ad0943464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loaders = [\n",
    "    PyPDFLoader(\"MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture01.pdf\"),    \n",
    "    PyPDFLoader(\"MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"MachineLearning-Lecture03.pdf\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05593a01-474d-47f6-969b-e19f953711c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2cb899-2246-440b-be71-701b7db77356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f85009f8-938e-49ff-a400-14172f38243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1500\n",
    "chunk_overlap = 150\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter (\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67136532-5a6a-49e5-8f95-160f47f5a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86897698-a466-4702-9809-acbe13d63a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7c24617-5549-4796-8f70-270c9e77102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of the class, and then we'll start to talk a bit about machine learning.  \n",
      "By way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \n",
      "I personally work in machine learning, and I've worked on it for about 15 years now, and \n",
      "I actually think that machine learning is the most exciting field of all the computer \n",
      "sciences. So I'm actually always excited about teaching this class. Sometimes I actually \n",
      "think that machine learning is not only the most exciting thing in computer science, but \n",
      "the most exciting thing in all of human endeavor, so maybe a little bias there.  \n",
      "I also want to introduce the TAs, who are all graduate students doing research in or \n",
      "related to the machine learning and all aspects of machine learning. Paul Baumstarck \n",
      "works in machine learning and computer vision. Catie Chang is actually a neuroscientist \n",
      "who applies machine learning algorithms to try to understand the human brain. Tom Do \n",
      "is another PhD student, works in computational biology and in sort of the basic \n",
      "fundamentals of human learning. Zico Kolter is the head TA — he's head TA two years \n",
      "in a row now — works in machine learning a nd applies them to a bunch of robots. And \n",
      "Daniel Ramage is — I guess he's not here  — Daniel applies l earning algorithms to\n"
     ]
    }
   ],
   "source": [
    "print(splits[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6781c3a4-af07-4ef5-bfba-feea5ced813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of the class, and then we'll start to talk a bit about machine learning.  \n",
      "By way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \n",
      "I personally work in machine learning, and I've worked on it for about 15 years now, and \n",
      "I actually think that machine learning is the most exciting field of all the computer \n",
      "sciences. So I'm actually always excited about teaching this class. Sometimes I actually \n",
      "think that machine learning is not only the most exciting thing in computer science, but \n",
      "the most exciting thing in all of human endeavor, so maybe a little bias there.  \n",
      "I also want to introduce the TAs, who are all graduate students doing research in or \n",
      "related to the machine learning and all aspects of machine learning. Paul Baumstarck \n",
      "works in machine learning and computer vision. Catie Chang is actually a neuroscientist \n",
      "who applies machine learning algorithms to try to understand the human brain. Tom Do \n",
      "is another PhD student, works in computational biology and in sort of the basic \n",
      "fundamentals of human learning. Zico Kolter is the head TA — he's head TA two years \n",
      "in a row now — works in machine learning a nd applies them to a bunch of robots. And \n",
      "Daniel Ramage is — I guess he's not here  — Daniel applies l earning algorithms to \n",
      "problems in natural language processing.  \n",
      "So you'll get to know the TAs and me much better throughout this quarter, but just from \n",
      "the sorts of things the TA's do, I hope you can already tell that machine learning is a \n",
      "highly interdisciplinary topic in which just the TAs find learning algorithms to problems \n",
      "in computer vision and biology and robots and language. And machine learning is one of \n",
      "those things that has and is having a large impact on many applications.  \n",
      "So just in my own daily work, I actually frequently end up talking to people like \n",
      "helicopter pilots to biologists to people in computer systems or databases to economists \n",
      "and sort of also an unending stream of people from industry coming to Stanford \n",
      "interested in applying machine learning methods to their own problems.  \n",
      "So yeah, this is fun. A couple of weeks ago, a student actually forwarded to me an article \n",
      "in \"Computer World\" about the 12 IT skills that employers can't say no to. So it's about \n",
      "sort of the 12 most desirable skills in all of IT and all of information technology, and \n",
      "topping the list was actually machine learning. So I think this is a good time to be \n",
      "learning this stuff and learning algorithms and having a large impact on many segments \n",
      "of science and industry.  \n",
      "I'm actually curious about something. Learning algorithms is one of the things that \n",
      "touches many areas of science and industries, and I'm just kind of curious. How many \n",
      "people here are computer science majors, are in the computer science department? Okay. \n",
      "About half of you. How many people are from EE? Oh, okay, maybe about a fifth. How\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7ff5c07-e2ad-4312-a675-9cc8f3c427b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea7810-abc7-4190-8078-d08072957ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-openai\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b512f36a-bcc3-4788-a033-7ead2e7b7041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1419cd22-fa63-4504-aada-deaadfbb4371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abab9c70-5680-415b-ae69-eab4e8ad398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "864c828e-b442-420a-bf26-d1c8d86bceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee1 = \"I enjoy drinking coffee in the morning.\"\n",
    "coffee2 = \"I love having a cup of filter coffee when I wake up\"\n",
    "market = \"The stock market had a big crash yesterday.\"\n",
    "mug = \"I crashed the stock of my coffee mug yesterday.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2502983-4f09-45b9-ae23-07b3eebdad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee1_embedding = embedding.embed_query(coffee1)\n",
    "coffee2_embedding = embedding.embed_query(coffee2)\n",
    "market_embedding = embedding.embed_query(market)\n",
    "mug_embedding = embedding.embed_query(mug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21a51760-fc9e-42a7-a5b3-3a46cfa2dfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.030784480273723602\n"
     ]
    }
   ],
   "source": [
    "print(coffee1_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8788766c-51a3-41ad-aab1-67cabbcc3072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7e194db-3057-4400-821c-e1345d35cab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.627351559087536)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array(coffee1_embedding), np.array(coffee2_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df26b3b3-3d7c-4a27-888e-af16c03f6c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.07100796107510074)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array(coffee1_embedding), np.array(market_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21b366f5-45f0-4caf-a949-63d9f4ebefd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5174512851028488)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array(market_embedding), np.array(mug_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294f263-f430-465c-8f00-81c81f0dc4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a13cb954-098f-4bfc-b7ec-c7d251086d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "!rm -rf ./docs/chroma1\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=\"docs/chroma1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6306865-1c71-4021-80f4-481a2730e8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8256\n",
      "drwxr-xr-x@ 4 abhinav  staff      128 Sep 27 15:54 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 3 abhinav  staff       96 Sep 27 15:54 \u001b[34m..\u001b[m\u001b[m\n",
      "-rw-r--r--@ 1 abhinav  staff  3268608 Sep 27 15:54 chroma.sqlite3\n",
      "drwxr-xr-x@ 6 abhinav  staff      192 Sep 27 15:54 \u001b[34mdb9a1965-b099-4cb0-aa27-9936088d8b18\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -al docs/chroma1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2bdc90f-42c0-4a16-883f-b21dc54ce41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the content about?\"\n",
    "docs = vectordb.similarity_search(question, \n",
    "                                  k=3,\n",
    "                                  filter={\"source\":\"MachineLearning-Lecture03.pdf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45b30f34-ccf1-4f19-b244-ade0a14daf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be8b3142-4ce1-4588-983c-2d4262c16ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='MachineLearning-Lecture03  \n",
      "Instructor (Andrew Ng):Okay. Good morning and welcome back to the third lecture of \n",
      "this class. So here’s what I want to do today, and some of the topics I do today may seem \n",
      "a little bit like I’m jumping, sort of, from topic to topic, but here’s, sort of, the outline for \n",
      "today and the illogical flow of ideas. In the last lecture, we talked about linear regression \n",
      "and today I want to talk about sort of an adaptation of that called locally weighted \n",
      "regression. It’s very a popular algorithm that’s actually one of my former mentors \n",
      "probably favorite machine learning algorithm.  \n",
      "We’ll then talk about a probable second interpretation of linear regression and use that to \n",
      "move onto our first classification algorithm, which is logistic regression; take a brief \n",
      "digression to tell you about something called the perceptron algorithm, which is \n",
      "something we’ll come back to, again, later this quarter; and time allowing I hope to get to \n",
      "Newton’s method, which is an algorithm for fitting logistic regression models.  \n",
      "So this is recap where we’re talking about in the previous lecture, remember the notation \n",
      "I defined was that I used this X superscript I, Y superscript I to denote the I training \n",
      "example. And when we’re talking about linear regression or linear least squares, we use \n",
      "this to denote the predicted value of “by my hypothesis H” on the input XI. And my \n",
      "hypothesis was franchised by the vector of grams as theta and so we said that this was' metadata={'page': 0, 'page_label': '1', 'creator': 'PScript5.dll Version 5.2.2', 'author': '', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creationdate': '2008-07-11T11:25:03-07:00', 'moddate': '2008-07-11T11:25:03-07:00', 'title': '', 'source': 'MachineLearning-Lecture03.pdf', 'total_pages': 16}\n"
     ]
    }
   ],
   "source": [
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ddd578e-b91c-4638-946b-329c1e857f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='So all right, online resources. The class has a home page, so it's in on the handouts. I \n",
      "won't write on the chalkboard — http:// cs229.stanford.edu. And so when there are \n",
      "homework assignments or things like that, we usually won't sort of — in the mission of \n",
      "saving trees, we will usually not give out many handouts in class. So homework \n",
      "assignments, homework solutions will be posted online at the course home page.  \n",
      "As far as this class, I've also written, and I guess I've also revised every year a set of \n",
      "fairly detailed lecture notes that cover the technical content of this class. And so if you \n",
      "visit the course homepage, you'll also find the detailed lecture notes that go over in detail \n",
      "all the math and equations and so on that I'll be doing in class.  \n",
      "There's also a newsgroup, su.class.cs229, also written on the handout. This is a \n",
      "newsgroup that's sort of a forum for people in the class to get to know each other and \n",
      "have whatever discussions you want to have amongst yourselves. So the class newsgroup \n",
      "will not be monitored by the TAs and me. But this is a place for you to form study groups \n",
      "or find project partners or discuss homework problems and so on, and it's not monitored \n",
      "by the TAs and me. So feel free to talk trash about this class there.  \n",
      "If you want to contact the teaching staff, please use the email address written down here, \n",
      "cs229-qa@cs.stanford.edu. This goes to an account that's read by all the TAs and me. So' metadata={'source': 'MachineLearning-Lecture01.pdf', 'page_label': '6', 'moddate': '2008-07-11T11:25:23-07:00', 'page': 5, 'creator': 'PScript5.dll Version 5.2.2', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'author': '', 'total_pages': 22, 'title': '', 'creationdate': '2008-07-11T11:25:23-07:00'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20b23496-c65e-4bf0-ad94-374e6acaf740",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did they say about matlab?\"\n",
    "docs = vectordb.similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30fadb87-ee18-4f63-9ef1-35f2ec0d7777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those homeworks will be done in either MATLAB or in Octave, which is sort of — I \n",
      "know some people call it a free version of MATLAB, which it sort of is, sort of isn't.  \n",
      "So I guess for those of you that haven't seen MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to \n",
      "write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than \n",
      "MATLAB, but it's free, and for the purposes of this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side comment for those of you that haven't seen \n",
      "MATLAB before I guess, once a colleague of mine at a different university, not at \n",
      "Stanford, actually teaches another machine learning course. He's taught it for many years. \n",
      "So one day, he was in his office, and an old student of his from, like, ten years ago came \n",
      "into his office and he said, \"Oh, professor, professor, thank you so much for your\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75292206-8f0c-4d33-b583-5069d6b71081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "into his office and he said, \"Oh, professor, professor, thank you so much for your \n",
      "machine learning class. I learned so much from it. There's this stuff that I learned in your \n",
      "class, and I now use every day. And it's helped me make lots of money, and here's a \n",
      "picture of my big house.\"  \n",
      "So my friend was very excited. He said, \"Wow. That's great. I'm glad to hear this \n",
      "machine learning stuff was actually useful. So what was it that you learned? Was it \n",
      "logistic regression? Was it the PCA? Was it the data networks? What was it that you \n",
      "learned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \n",
      "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, \n",
      "and we'll actually have a short MATLAB tutorial in one of the discussion sections for \n",
      "those of you that don't know it.  \n",
      "Okay. The very last piece of logistical thing is the discussion sections. So discussion \n",
      "sections will be taught by the TAs, and attendance at discussion sections is optional, \n",
      "although they'll also be recorded and televised. And we'll use the discussion sections \n",
      "mainly for two things. For the next two or three weeks, we'll use the discussion sections \n",
      "to go over the prerequisites to this class or if some of you haven't seen probability or \n",
      "statistics for a while or maybe algebra, we'll go over those in the discussion sections as a \n",
      "refresher for those of you that want one.\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "316d645d-1343-4a8e-9a70-92dd7b6f13c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So later this quarter, we'll use the discussion sections to talk about things like convex \n",
      "optimization, to talk a little bit about hidden Markov models, which is a type of machine \n",
      "learning algorithm for modeling time series and a few other things, so extensions to the \n",
      "materials that I'll be covering in the main lectures. And attendance at the discussion \n",
      "sections is optional, okay?  \n",
      "So that was all I had from logistics. Before we move on to start talking a bit about \n",
      "machine learning, let me check what questions you have. Yeah?  \n",
      "Student : [Inaudible] R or something like that?  \n",
      "Instructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \n",
      "welcome to use R, but I would strongly advise against it, mainly because in the last \n",
      "problem set, we actually supply some code that will run in Octave but that would be \n",
      "somewhat painful for you to translate into R yourself. So for your other assignments, if \n",
      "you wanna submit a solution in R, that's fine. But I think MATLAB is actually totally \n",
      "worth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \n",
      "bit more often for various reasons. Yeah?  \n",
      "Student : For the [inaudible] project [inaudible]?  \n",
      "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \n",
      "groups of three, or you're welcome to do it by yourself or in groups of two. Grading is the \n",
      "same regardless of the group size, so with a larger group, you probably — I recommend\n"
     ]
    }
   ],
   "source": [
    "print(docs[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0af1731-71a3-4ab6-a968-682dabe9d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did they say about matlab?\"\n",
    "docs = vectordb.max_marginal_relevance_search(question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79ff9b00-648e-425f-b884-0c4df4dfcdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those homeworks will be done in either MATLAB or in Octave, which is sort of — I \n",
      "know some people call it a free version of MATLAB, which it sort of is, sort of isn't.  \n",
      "So I guess for those of you that haven't seen MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to \n",
      "write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than \n",
      "MATLAB, but it's free, and for the purposes of this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side comment for those of you that haven't seen \n",
      "MATLAB before I guess, once a colleague of mine at a different university, not at \n",
      "Stanford, actually teaches another machine learning course. He's taught it for many years. \n",
      "So one day, he was in his office, and an old student of his from, like, ten years ago came \n",
      "into his office and he said, \"Oh, professor, professor, thank you so much for your\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a836a325-6550-4f29-8079-c6c2ebcd43f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least squares regression being a bad idea for classification problems and then I did a \n",
      "bunch of math and I skipped some steps, but I’m, sort of, claiming at the end they’re \n",
      "really the same learning algorithm?  \n",
      "Student:[Inaudible] constants?  \n",
      "Instructor (Andrew Ng):Say that again.  \n",
      "Student:[Inaudible]  \n",
      "Instructor (Andrew Ng):Oh, right. Okay, cool.\n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab19d2a5-96f0-4ea3-900f-a11440bc83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata Self Query Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cbc55aae-e1fe-483b-b89c-ab4c890e788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7e92455-3497-4017-96d2-23d68d9118c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54942125-a2a9-4091-af3e-868c563df1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"lecture notes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41681197-0213-4f3b-8562-5d79b9dc043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\", \n",
    "        description=\"The lecture the chunk is from, should be one of `MachineLearning-Lecture01.pdf`, `MachineLearning-Lecture02.pdf`, or `MachineLearning-Lecture03.pdf`\",        \n",
    "        type=\"string\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\", \n",
    "        description=\"The page from the lecture\",        \n",
    "        type=\"string\"        \n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba0d9082-6937-4461-b63f-4eb65b89bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,    \n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0a23ae14-8eb8-466b-80ec-6cd91befa433",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did they say about regression in the third lecture\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6461b2b2-2318-4ff8-a5e2-d75c156bf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3e182f46-3b43-4427-b2a7-16755ebbf66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a438644e-7989-4c91-a58f-433f8a19b5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='predictions of your hypothesis have changed completely if your threshold – your \n",
      "hypothesis at Y equal both 0.5. Okay? So –  \n",
      "Student:In between there might be an interval where it’s zero, right? For that far off \n",
      "point?  \n",
      "Instructor (Andrew Ng):Oh, you mean, like that?  \n",
      "Student:Right.  \n",
      "Instructor (Andrew Ng):Yeah, yeah, fine. Yeah, sure. A theta set like that so. So, I \n",
      "guess, these just – yes, you’re right, but this is an example and this example works. This \n",
      "–  \n",
      "Student:[Inaudible] that will change it even more if you gave it all –  \n",
      "Instructor (Andrew Ng):Yeah. Then I think this actually would make it even worse. \n",
      "You would actually get a line that pulls out even further, right? So this is my example. I \n",
      "get to make it whatever I want, right? But the point of this is that there’s not a deep \n",
      "meaning to this. The point of this is just that it could be a really bad idea to apply linear \n",
      "regression to classification algorithm. Sometimes it work fine, but usually I wouldn’t do \n",
      "it. So a couple of problems with this. One is that, well – so what do you want to do for \n",
      "classification? If you know the value of Y lies between zero and one then to kind of fix \n",
      "this problem let’s just start by changing the form of our hypothesis so that my hypothesis \n",
      "always lies in the unit interval between zero and one. Okay? So if I know Y is either zero \n",
      "or one then let’s at least not have my hypothesis predict values much larger than one and' metadata={'author': '', 'creator': 'PScript5.dll Version 5.2.2', 'page_label': '12', 'total_pages': 16, 'title': '', 'moddate': '2008-07-11T11:25:03-07:00', 'creationdate': '2008-07-11T11:25:03-07:00', 'source': 'MachineLearning-Lecture03.pdf', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'page': 11}\n"
     ]
    }
   ],
   "source": [
    "print(docs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5acdaad-28f2-4eb8-8066-01788a8086b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
